{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOGPOUD2Ii0cV20SYn2CzNR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/Exercise/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EA%B3%BC%EC%99%B8_Exercise3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzSfSlvJQQCN",
        "outputId": "8e53e4b8-9e6e-4052-bc46-e2850326803b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "qCgOrM1mTe67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-7wiUarAeY0",
        "outputId": "bccdf294-3cc9-4310-a643-2f99173e1492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOzydKZVArm4",
        "outputId": "fbb21134-bdc4-48da-f7dd-1c2bd8274291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0N_WOZUUA49I",
        "outputId": "8d35d43f-1b11-4624-a04a-d7cf251b27fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "icgpI6l8BcgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn"
      ],
      "metadata": {
        "id": "wYSgBa8SBgzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv240mBwBi6d",
        "outputId": "9f60367f-4c10-44c7-d35c-2e9a63bb1282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1HvHxObCYtVF",
        "outputId": "c632b153-8b62-4888-fe5e-246c6a805b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataserver, use_threads)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0;31m# Create the main window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m         \u001b[0mtop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'+50+50'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3b02390c7677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;31m# function should make a new copy of self to use?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdownload_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_interactive_download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m                 \u001b[0mDownloaderGUI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTclError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m                 \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0mDownloaderShell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'd'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_interactive_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'u'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_interactive_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/downloader.py\u001b[0m in \u001b[0;36m_simple_interactive_download\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Download which package (l=list; x=cancel)?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  Identifier> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'l'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                     self._ds.list(self._ds.download_dir, header=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "id": "GMtQiiTXYyVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "Um333dPJ42Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=[\n",
        "      ['1000', 'Steve', 98.72],\n",
        "      ['1001', 'James', 78.09],\n",
        "      ['1002', 'Dane', 98.43],\n",
        "      ['1003', 'Jane', 64.19],\n",
        "      ['1004', 'Sean', 81.30],\n",
        "      ['1005', 'Tony', 99.14]\n",
        "]\n",
        "df=pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDVGFVKPQegB",
        "outputId": "45d848de-f94d-4649-c5b0-e58c9f0e5666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0      1      2\n",
            "0  1000  Steve  98.72\n",
            "1  1001  James  78.09\n",
            "2  1002   Dane  98.43\n",
            "3  1003   Jane  64.19\n",
            "4  1004   Sean  81.30\n",
            "5  1005   Tony  99.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sr=pd.Series([17000, 18000, 1000, 5000], index=['Pizza', 'Chicken', 'Coke', 'Beer'])\n",
        "print('시리즈 출력:')\n",
        "print('-'*20)\n",
        "print(sr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-r9WoalUHa1",
        "outputId": "d30bef34-dcd0-488c-fb87-9f3b9f420ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시리즈 출력:\n",
            "--------------------\n",
            "Pizza      17000\n",
            "Chicken    18000\n",
            "Coke        1000\n",
            "Beer        5000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('시리즈의 값: {}', format(sr.values))\n",
        "print('시리즈의 인덱스:{}', format(sr.index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJGRwd73VDGj",
        "outputId": "99dad2f7-70f3-49f4-d6cc-8e52edc021db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "시리즈의 값: {} [17000 18000  1000  5000]\n",
            "시리즈의 인덱스:{} Index(['Pizza', 'Chicken', 'Coke', 'Beer'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "otTr7EiMqgII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "values=[[1,2,3],[4,5,6],[7,8,9]]\n",
        "index=['one', 'two', 'three']\n",
        "colums=['A', 'B', 'C']\n",
        "\n",
        "df=pd.DataFrame(values, index=index, colums=colums)\n",
        "\n",
        "print('데이터프레임 출력:')\n",
        "print('-'*18)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "lnxZt19krJrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHzIAzUMrWZk",
        "outputId": "2cc6b980-04ee-4c68-98c6-227a0bea1858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_z8ZSqFsE0H",
        "outputId": "6e8507a9-2ea4-4f93-e8ef-476796f554e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "values=[[1,2,3],[4,5,6],[7,8,9]]\n",
        "index=['one', 'two', 'three']\n",
        "columns=['A', 'B', 'C']\n",
        "\n",
        "df=pd.DataFrame(values, index=index, columns=columns)\n",
        "\n",
        "print('데이터프레임 출력:')\n",
        "print('-'*18)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eXD5QU7sMAB",
        "outputId": "e01edc51-6496-4132-c396-1f84ab32460e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터프레임 출력:\n",
            "------------------\n",
            "       A  B  C\n",
            "one    1  2  3\n",
            "two    4  5  6\n",
            "three  7  8  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('데이터프레임의 인덱스:{}' .format(df.index))\n",
        "print('데이터프레임의 열이름:{}' .format(df.columns))\n",
        "print('데이터프레임의 값:')\n",
        "print('-'*18)\n",
        "print(df.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgVnRDOdsShR",
        "outputId": "8a21792f-8934-4632-f8d5-49444c6c2be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터프레임의 인덱스:Index(['one', 'two', 'three'], dtype='object')\n",
            "데이터프레임의 열이름:Index(['A', 'B', 'C'], dtype='object')\n",
            "데이터프레임의 값:\n",
            "------------------\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#리스트 생성하기\n",
        "data=[\n",
        "      ['1000', 'Steve', 90.72],\n",
        "      ['1001', 'James', 98.43],\n",
        "      ['1002', 'Dan', 98.43],\n",
        "      ['1003', 'Jane', 64.19],\n",
        "      ['1004', 'Pam', 81.30], \n",
        "      ['1005', 'Tony', 99.14]\n",
        "]\n",
        "\n",
        "df=pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU9eGxsiuXGj",
        "outputId": "1134dec6-b9b7-48db-ce56-46fb6fe727ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0      1      2\n",
            "0  1000  Steve  90.72\n",
            "1  1001  James  98.43\n",
            "2  1002    Dan  98.43\n",
            "3  1003   Jane  64.19\n",
            "4  1004    Pam  81.30\n",
            "5  1005   Tony  99.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#딕셔너리로 생성하기\n",
        "data={\n",
        "    '학번':['1000', '1001', '1002', '1003', '1004', '1005'],\n",
        "    '이름':['Steve', 'James', 'Dan', 'Jane', 'Pam', 'Tony'],\n",
        "    '점수':[90.72, 78.09, 98.43, 64.19, 81.30, 99.14]\n",
        "}\n",
        "df=pd.DataFrame(data)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxyfvy9gycaW",
        "outputId": "a71932a8-4c0a-4c0e-a7b9-5c5dd800da73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     학번     이름     점수\n",
            "0  1000  Steve  90.72\n",
            "1  1001  James  78.09\n",
            "2  1002    Dan  98.43\n",
            "3  1003   Jane  64.19\n",
            "4  1004    Pam  81.30\n",
            "5  1005   Tony  99.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터프레임 조회하기\n",
        "df.head(3)\n",
        "df.tail(3)\n",
        "print(df.head(3))\n",
        "print(df.tail(3))\n",
        "print(df['학번'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URnhANtHzaMz",
        "outputId": "db16ec3f-29bc-4c58-ead7-7b7108d88338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     학번     이름     점수\n",
            "0  1000  Steve  90.72\n",
            "1  1001  James  78.09\n",
            "2  1002    Dan  98.43\n",
            "     학번    이름     점수\n",
            "3  1003  Jane  64.19\n",
            "4  1004   Pam  81.30\n",
            "5  1005  Tony  99.14\n",
            "0    1000\n",
            "1    1001\n",
            "2    1002\n",
            "3    1003\n",
            "4    1004\n",
            "5    1005\n",
            "Name: 학번, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('scores.csv')\n",
        "print(df)\n",
        "print(df.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6j7Plo20SGP",
        "outputId": "10c07d6d-f8d0-40e2-b671-b77736d5afa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      SID       Name  Score\n",
            "0  1000.0    Steve    90.72\n",
            "1  1001.0     James   78.09\n",
            "2  1002.0      Dan    98.43\n",
            "3  1003.0      Jane   64.19\n",
            "4  1004.0       Pam   81.30\n",
            "5  1005.0      Tony   99.14\n",
            "6     NaN        NaN    NaN\n",
            "RangeIndex(start=0, stop=7, step=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V5zsI_lWMwG",
        "outputId": "3d72b729-17ba-4bb7-a6f9-d89a55bde7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "rsZwgtvhYPBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec=np.array([1,2,3,4,5])\n",
        "print(vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpfYZtLHYSzo",
        "outputId": "09addec8-1b7d-48a0-c541-ac0e7cebd782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3 4 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat=np.array([[10,20,30],[60,70,80]])\n",
        "print(mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoUaABdacG1l",
        "outputId": "535e3f3b-2ffb-418d-f0ba-6ae1d0b78e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[10 20 30]\n",
            " [60 70 80]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('vec의 타입:',type(vec))\n",
        "print('mat의 타입:', type(mat))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXaHEh1ncTgp",
        "outputId": "72b5ba77-a65e-4993-ef51-79d7b08e9dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vec의 타입: <class 'numpy.ndarray'>\n",
            "mat의 타입: <class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_mat=np.zeros((2,3))\n",
        "one_mat=np.ones((2,3))\n",
        "print(zero_mat)\n",
        "print(one_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d777iAifcg3",
        "outputId": "0a912ae1-f25d-4747-8b74-ab2593e805f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[1. 1. 1.]\n",
            " [1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "same_value_mat=np.full((2,2),7)\n",
        "print(same_value_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeVc5jAKforO",
        "outputId": "47730f73-d42c-4e87-c5ac-6666cc273adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7 7]\n",
            " [7 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eye_mat=np.eye(3)\n",
        "print(eye_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HJ_vR0ef2Th",
        "outputId": "f754c361-5c35-49c1-ef9b-93f09bd2f7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_mat=np.random.random((2,2))\n",
        "print(random_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ0uB2Bif_9U",
        "outputId": "699f5f56-03f1-4e2a-e817-a1ac44089ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.28614883 0.53326901]\n",
            " [0.4638774  0.62918455]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C3rec3KgWkk",
        "outputId": "db51c1bd-cb51-4c29-c40f-66b2f6a59c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "range_vec=np.arrange(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "0Zwdc9wps6ch",
        "outputId": "2b353145-2b7a-4660-9010-aa8f244feaef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-369b08e7c5c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrange_vec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORYj1kr4tAZx",
        "outputId": "7bb250d6-8998-4e41-8041-123c70d38b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "GNgUssRatDie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "x2GyUqL2xX0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "range_vec=np.arange(10)\n",
        "print(range_vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gRq9CeHxl7O",
        "outputId": "7e027e74-6389-4c26-c825-87f7d8ff6e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2 3 4 5 6 7 8 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=2\n",
        "range_n_step_vec=np.arange(1,20,n)\n",
        "print(range_n_step_vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFk3SaR2zTKg",
        "outputId": "d7346786-0de4-4f4b-e8cf-30fd80688cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1  3  5  7  9 11 13 15 17 19]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reshape_mat=np.array(np.arange(30)).reshape((5,6))\n",
        "print(reshape_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_-TdONQz2sf",
        "outputId": "ac3912f7-7d3c-47c8-f99b-070fe997a80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat=np.array([[1,2,3],[4,5,6]])\n",
        "print(mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnFT3djg0GCf",
        "outputId": "6ab6d303-c6c3-468e-8043-426ef8e61295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slicing_mat=mat[0,:]\n",
        "print(slicing_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYrjvMfJ0e2B",
        "outputId": "5e7058fb-f4b4-409c-d1a2-9efe26ec872e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slicing_mat=mat[:, 1]\n",
        "print(slicing_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERLM15dy05SW",
        "outputId": "6cea755d-6660-4bbd-c2f5-ea9b169f391d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat=np.array([[1,2], [4,5], [7,8]])\n",
        "print(mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7FL1RkI1B4a",
        "outputId": "619c9d5c-0d08-404f-d120-495f97dbab8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2]\n",
            " [4 5]\n",
            " [7 8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mat[1,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msi25IlM1XhM",
        "outputId": "c58c9993-fa60-4eba-ed72-029596c6bf4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexing_mat=mat[[2,1], [0,1]]\n",
        "print(indexing_mat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "if2_-wvP1msx",
        "outputId": "02dcd387-7094-492a-8487-f9de2097e0bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array([1,2,3])\n",
        "y=np.array([4,5,6])\n",
        "result=x+y\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m27BUQrJ1x5k",
        "outputId": "3e3c8d28-a991-404e-8ed4-a87be61647da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5 7 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=x-y\n",
        "print(result)\n",
        "result=result*x\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDd_g7DS3z3J",
        "outputId": "b7ebab4f-c8b2-4eec-d5ed-df0bc75e119a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-3 -3 -3]\n",
            "[-3 -6 -9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat1=np.array([[1,2],[3,4]])\n",
        "mat2=np.array([[5,6],[7,8]])\n",
        "mat3=np.dot(mat1,mat2)\n",
        "print(mat3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzeDu9yG3_ns",
        "outputId": "17aac0a7-099e-4a26-f9ee-5ab215e84f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[19 22]\n",
            " [43 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMsGDKZg4uCs",
        "outputId": "968182ae-b2b3-42be-fbd6-6736f8f417fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "O0bznyn28wR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl"
      ],
      "metadata": {
        "id": "XGY-3CqO85R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('test')\n",
        "plt.plot([1,2,3,4],[2,4,8,6])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "isAKDALM9Lmy",
        "outputId": "9099227b-8acd-481b-c26c-02f104ec0181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('test')\n",
        "plt.plot([1,2,3,4],[2,4,8,6])\n",
        "plt.xlabel('hours')\n",
        "plt.ylabel('score')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "mLe7wr5k--WD",
        "outputId": "582c35fb-b77f-4990-81f0-df7968346c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('students')\n",
        "plt.plot([1,2,3,4,],[2,4,8,6])\n",
        "plt.plot([1.5, 2.5, 3.5, 4.5], [3,5,8,10])\n",
        "plt.xlabel('hours')\n",
        "plt.ylabel('score')\n",
        "plt.legend(['A student', 'B student'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ei-ewLb1_QX0",
        "outputId": "c89d85ac-dead-4879-d541-46764152420a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxMVx/H8c8vERI7se+7qi2IXS21L6WLotTWqu6PPm211dJVd21pq1o7LaFUS+17aa0RlCZ2sQWJECQSspznjxkeUiFiZu4k83u/Xl5muXPP18Vvbs499xwxxqCUUspzeFkdQCmllGtp4VdKKQ+jhV8ppTyMFn6llPIwWviVUsrDaOFXSikPo4VfqQwQkXARaWN1DqUyQgu/8jgi8q6I/GR1DnCvLMpzaOFXSikPo4VfZWki8rqInBCRiyKyV0Q6A28CPUUkVkR22re7oesm9Zm4iPQVkSMiEi0ib6Vqw0tE3hCRg/b3fxaRgvb3yomIEZH+InJURM5c/byIdEgjywAROWTPfFhE+jj7OCnPooVfZVkiUhV4AahvjMkDtAf2AB8Bs40xuY0xtdOxn3uBcUBfoATgD5S6bpMXgQeBFvb3zwFjU+2mGVAVaA28LSLVjDFLU2cRkVzA10BHe+YmwI4MHQCl0qCFX2VlyUAO4F4R8THGhBtjDmZgP92BhcaYdcaYy8AIIOW6958B3jLGHLe//y7QXUSyXbfNe8aYeGPMTmAncKsvnBSghoj4GWNOGmP+yUBmpdKkhV9lWcaYA8BL2ApxpIjMEpESGdhVCeDYdfuNA6Kve78s8KuIxIhIDBCG7Uun6HXbnLru8SUgdxqZ44Ce2L5MTorIIhG5JwOZlUqTFn6VpRljZhpjmmErzgb41P57anFAzuueF7vu8Umg9NUnIpITW3fPVcewdc3kv+6XrzHmRHoi3iTzMmNMW6A4tq6pCenYj1LppoVfZVkiUlVE7heRHEACEI+tG+U0UE5Erv/3vwPoJSI+IhKIrXvnqrlAFxFpJiLZgfe58f/O98CHIlLW3m5hEemWzpg3ZBGRoiLSzd7XfxmI5cZuJaXumhZ+lZXlAD4BzmDraikCDAPm2N+PFpEQ++MRQEVsF2bfA2Ze3Ym9j/15+2sn7dscv66dMcACYLmIXAQ2AQ3TmTF1Fi/gZSACOIvtgvGz6dyXUukiuhCLUkp5Fj3jV0opD6OFXymlPIwWfqWU8jBa+JVSysNku/0m1itUqJApV66c1TGUUipT2bZt2xljTOHUr2eKwl+uXDmCg4OtjqGUUpmKiBy52eva1aOUUh5GC79SSnkYLfxKKeVhMkUf/80kJiZy/PhxEhISrI6S6fn6+lKqVCl8fHysjqKUcoFMW/iPHz9Onjx5KFeuHCJidZxMyxhDdHQ0x48fp3z58lbHUUq5gNO6ekRksohEisju614rKCIrRGS//fcCGd1/QkIC/v7+WvTvkojg7++vPzkp5UGc2cc/FeiQ6rU3gFXGmMrAKvvzDNOi7xh6HJXyLE4r/MaYddimlb1eN2Ca/fE0bOuUKqWUSu3sIVjyBiQnOXzXrh7VU9QYc9L++BQ3Lk13AxEZLCLBIhIcFRXlmnQZ8NtvvyEi7Nmz544+N3r0aC5dunTH7eXOfdMV+9Jl6tSpREREZPjzSikXSDgPy0fA2IYQMh1O73J4E5YN5zS2hQDSXAzAGDPeGBNojAksXPhfdxy7jaCgIJo1a0ZQUNAdfS6jhf9uaOFXyo0lJ0HwZPi6Lmz4Bmr2gBe3QYk6Dm/K1YX/tIgUB7D/Huni9h0qNjaWP//8k0mTJjFr1qybbhMXF0fnzp2pXbs2NWrUYPbs2Xz99ddERETQqlUrWrVqBdx4Jj937lwGDBgAwOHDh2ncuDE1a9Zk+PDhN+z7888/p379+tSqVYt33nkHgPDwcKpVq8ZTTz1F9erVadeuHfHx8cydO5fg4GD69OlDQEAA8fHxTjgiSqkMObgGfmgOC/8LhavC4LXw4FjIW9wpzbl6OOcCoD+25fD6A/MdsdP3fv+H0IgLjtjVNfeWyMs7D1S/5Tbz58+nQ4cOVKlSBX9/f7Zt20a9evVu2Gbp0qWUKFGCRYsWAXD+/Hny5cvHl19+yZo1ayhUqNAt2xgyZAjPPvss/fr1Y+zYsddeX758Ofv372fLli0YY+jatSvr1q2jTJky7N+/n6CgICZMmECPHj345ZdfePzxx/n2228ZNWoUgYGBGTwqSimHOrMflg+HfUshf1noMR2qdQUnD7hw5nDOIGAjUFVEjovIk9gKflsR2Q+0sT/PtIKCgujVqxcAvXr1uml3T82aNVmxYgWvv/4669evJ1++fHfUxl9//cVjjz0GQN++fa+9vnz5cpYvX06dOnWoW7cue/bsYf/+/QCUL1+egIAAAOrVq0d4eHhG/nhKKWeJPwdLh8F3jSD8L2j7PrywFe7t5vSiD0484zfGPJbGW60d3dbtzsyd4ezZs6xevZpdu3YhIiQnJyMifP755zcMj6xSpQohISEsXryY4cOH07p1a95+++1/7e/6z6QeU3+z4ZbGGIYNG8bTTz99w+vh4eHkyJHj2nNvb2/t1lHKXSQn2vrx135su4hbtx+0egtyF3FpDJ2rJ4Pmzp1L3759OXLkCOHh4Rw7dozy5cuzfv36G7aLiIggZ86cPP744wwdOpSQkBAA8uTJw8WLF69tV7RoUcLCwkhJSeHXX3+99nrTpk2vXT+YMWPGtdfbt2/P5MmTiY2NBeDEiRNERt76kknqNpVSLrR/BYxrAkteg2K14Jk/4YExLi/6oIU/w4KCgnjooYdueO2RRx75V3fPrl27aNCgAQEBAbz33nvXLtAOHjyYDh06XLu4+8knn9ClSxeaNGlC8eL/v6AzZswYxo4dS82aNTlx4sS119u1a0fv3r2vXfjt3r37bYv6gAEDeOaZZ/TirlKuFBkGPz4MM7qDSYHHZkG/+VDU9T0VV4ltVKV7CwwMNKkXYgkLC6NatWoWJcp69Hgq5WBx0bD2IwieAjlyQ4s3oP4gyJbdZRFEZJsx5l+jOTLtJG1KKeWWkq7AlvHwx2dwJRbqPwkth0HOglYnu0YLv1JKOYIxsHexbXjm2UNQqS20GwlF7rE62b9o4VdKqbt1apdteGb4eihUFfr8ApXbWJ0qTVr4lVIqo2IjYfUHEPIj+BWATqOg3kDwdu/S6t7plFLKHSUmwKbvYP2XkBQPjZ+H5q/ain8moIVfKaXSyxgI/Q1WvA0xR6FqZ2j3AfhXtDrZHdFx/HfB29ubgIAAateuTd26ddmwYUO6P6vTMiuVyZwIgSkdYc4AyJEX+i2Ax2ZmuqIPWvjvip+fHzt27GDnzp18/PHHDBs2LN2f1WmZlcokLkTAr8/AhFYQfcB2t+3T66BCC6uTZZgWfge5cOECBQr8u39Pp2VWKpO6cgnWfgrf1IPdv0DTl+DFEKg3ALy8rU53V7JGH/+SN2zDqRypWE3oeOvJQ+Pj4wkICCAhIYGTJ0+yevXqf22j0zIrlcmkpMDuubDyXbhwwjZjZpv3oGB5q5M5jJ7x34WrXT179uxh6dKl9OvXj9RTYOi0zEplIse2wKS2MO8pyFUIBi6xzZGfhYo+ZJUz/tucmbtC48aNOXPmDFFRURQp8v/Z9nRaZqUygZijtjP83b9A7mLw4Dio1Qu8sua5cdb8U1lgz549JCcn4+/vf8PrOi2zUm7sciys+gC+rQ97FkHz12zr3Ab0zrJFHyw64xeRIcBTgAATjDGjrchxt6728YPtDHzatGl4e9940WfXrl0MHToULy8vfHx8GDduHPD/aZlLlCjBmjVrrk3LXLhwYQIDA68V9DFjxtC7d28+/fRTunXrdm2/7dq1IywsjMaNGwO2i8M//fTTv9q/3tVpmf38/Ni4cSN+fn4OPR5KZRopKbBzpq3ox56Cmo9C63cgf2mrk7mEy6dlFpEawCygAXAFWAo8Y4w5kNZndFpm59PjqTxG+F+wbBic3AklA6HDJ1C6vtWpnMKdpmWuBmw2xlwCEJE/gIeBzyzIopTyFGcP2+64DVsAeUvBwxOhZneXrHHrbqwo/LuBD0XEH4gHOgHBqTcSkcHAYIAyZcq4NKBSKgtJuADrR8GmceCVDVoNt82tkz2n1cks4/LCb4wJE5FPgeVAHLADSL7JduOB8WDr6kljXzcd8aLuTGZYhU2pO5aSDCHTYfVIuHQGAvrA/SMgb/HbfzaLs+TirjFmEjAJQEQ+Ao7f6T58fX2Jjo7G399fi/9dMMYQHR2Nr6+v1VGUcpxDa2HpmxD5D5RpAh3mQok6VqdyG1aN6ilijIkUkTLY+vcb3ek+SpUqxfHjx4mKinJ8QA/j6+tLqVKlrI6h1N07c8C2Ata+JZC/LDw6zXbnrZ4c3sCqG7h+sffxJwLPG2Ni7nQHPj4+lC+fte6mU0plUPw52xq3W8ZDNj9o8y40fBZ89CfZm7Gqq+c+K9pVSmUxyYkQPAXWfgTxMVC3H9w/HHIXuf1nPVjWmLJBKeV59q+AZW/CmX1Qvjm0/8g2uaK6LS38SqnMJTIMlr0FB1dBwQrQKwiqdtR+/DughV8plTnERdu6dIKnQPbctjP8+k9BtuxWJ8t0tPArpdxb0hXbRds/PoMrsRD4BLQcBrn8b/9ZdVNa+JVS7skY2LvYNjzz7CGo1AbafQhF7rE6WaanhV8p5X5O7bJduD28DgpVhT5zoXJbq1NlGVr4lVLuIzbSNsVCyHTwyw8dP4fAgeDtY3WyLEULv1LKeokJsHkcrPsCkuKh0XPQYij4FbA6WZakhV8pZR1jIHQ+rBhhW/6wSkdoNxIKVbI6WZamhV8pZY2I7baJ1I5ugCLVod98qNDS6lQeQQu/Usq1LpyEVe/blj7MWQi6jLZNteCV9rKhyrG08CulXOPKJdj4Lfz5FaQkQdMhcN8r4JvP6mQeRwu/Usq5jIFdc2HlO3DhBFTrCm3fh4I6u65VtPArpZzn2FZY+gacCIZiteDhCVCuqdWpPJ4WfqWU48Ucg5Xvwu65kLsodPsOaj8GXl5WJ1No4VdKOdLlWPhrNGz4xva8+VBo+hLkyG1tLnUDq5Ze/C8wCDDALmCgMSbBiixKKQdISYGdQbbROrGnoEZ32ypY+UtbnUzdhMsLv4iUBP4D3GuMiReRn4FewFRXZ1HKHSUmp+AtgpdXJplf/sgGWDoMTu6AkoHQ80co3cDqVOoWrOrqyQb4iUgikBOIsCiHUm7l/KVEeo7fSOzlJIZ1rEanmsUQd11gJCUF1oyE9V9A3pK2C7c1ums/fibg8r8hY8wJYBRwFDgJnDfGLE+9nYgMFpFgEQmOiopydUylXO5yUjKDfwzmYFQsvj7ePD8zhB4/bOTv4zFWR/u3xHiYO9BW9Ov2hxeCoVYPLfqZhMv/lkSkANANKA+UAHKJyOOptzPGjDfGBBpjAgsXLuzqmEq5VEqKYeicv9l8+CyjHq3Nspea89FDNTkUFUfXb//i5Z93cOq8m1wGi42EqV1sc+y0GwkPjIHsOa1Ope6AFV/PbYDDxpgoY0wiMA9oYkEOpdzGZ8v2smBnBK91qEq3gJJ4ewm9G5ZhzdCWPN2iAgt3nqTVqLWMWbmf+CvJ1gU9HQoTWkNkKPT8CZq8qGvdZkJWFP6jQCMRySm2zsvWQJgFOZRyC9M3hvP9Hwd5vFEZnm1R8Yb38vr6MKxjNVa+3IKWVQvz1cp93P/FWn7bfoKUFOPaoAdWwuT2kHwFBi6Gal1c275yGCv6+DcDc4EQbEM5vYDxrs6hlDtYEXqadxf8Q5tqRXj3geppXsgt45+TcY/XY9bgRhTMlZ2XZu/g4XEb2HbknGuCbp0EM3pA/rLw1CooUcc17SqnEGNcfNaQAYGBgSY4ONjqGEo51Paj53hswiaqFs1D0OBG5MyevkF2KSmGX0KO89myvURdvEzX2iV4veM9lMzv5/iQKcmwfARsGguV20P3SZAjj+PbUU4hItuMMYH/el0Lv1KuF34mjkfGbSBXjmzMe64JhXLnuON9xF1OYtzag0xYfwiAwc0r8EyLiuTK4aBR2pdjYd5TtgXPGz4D7T/SqZMzmbQKv469UsrFomMvM2DKFlKMYerA+hkq+gC5cmTj1fZVWf1qS9pXL8Y3qw/QatRa5gQfu/v+/wsRMKUj7FtqW/e246da9LMQLfxKuVD8lWQGTQ/m5PkEJvYPpELhu5/DpmR+P75+rA6/PNuEEvn9GDr3b7qO/ZPNh6IztsOTO2HC/XD2EPT+GRoOvuuMyr1o4VfKRZJTDENmbWfHsRjG9KpDvbIFHbr/emULMO/ZJozuGUB07BV6jt/Esz9t42j0pfTvZM9imNwBxBueWAaV2zo0o3IPWviVcgFjDO///g/LQ0/zdpd76VCjmFPa8fISHqxTktWvtOTltlVYuzeKNl/+wcdLwriYkHirgLBxLMzqDYXvsY3cKVbDKRmV9bTwK+UCE9YfYtrGIwxqVp6BTZ2/8pRfdm/+07oya15tyQO1S/DDH4do+flaZm4+SnLq/v/kJFj0Cix7E6o9AAMWQR7nfDEp96CFXykn+31nBB8t3kPnWsV5s1M1l7ZdLJ8vX/SozYIXmlKhcC7e/HUXnb9ez18Hztg2SDgPMx+F4Em2efMfnabTL3gAHc6plBNtPhRN30lbCCidn+lPNsDXx7qRMcYYFu86xcdLwjh+Lp6elVL44NIHZI85CF2+grr9LMumnCOt4Zy6ApdSTrL/9EWemh5M6YJ+jO9Xz9KiDyAidK5VnNbVirBwyQJabhtCPEnMqvIV3e55jHyWplOupF09SjlB5IUEBkzZSvZs3kwd2ID8ObNbHeka330L6P73MxTIn5+JVX7gnd3+tBi1hmkbwklMTrE6nnIBLfxKOVjs5SQGTt3KuUtXmDKgPqULukmfuTG2+fPnDIDiAXgPXs0rfR5g4YvNqFYsL+8s+IeOY9azZm+k1UmVk2nhV8qBEpNTeH5GCHtOXWRsn7rULOUmHShJV2D+87Y1cWs+Cv3mQ65CAFQvkY+ZTzVkfN96JCWnMHDKVvpP3sL+0xctDq2cRQu/Ug5ijGH4r7v5Y18UHz5Yg1ZVi1gdyebSWfjxIdgxA1q8YVsi0cf3hk1EhHbVi7H8vy0Y3rkaIUfP0WHMet6ev5uzcVcsCq6cRS/uKuUgX686wOzgY7x4fyV6NShjdRyb6IMwswfEHLUV/Fo9brl59mxeDLqvAg/VKcnolfuZsfkov24/wZDWlenXuBzZs+m5Ylagf4tKOcCc4GN8tXIfD9ctycttq1gdx+bIBpjY2nbG32/BbYv+9fxz5+CDB2uwZMh9BJTOz8hFYbQfvY7l/5wiMwwBV7dmxZq7VUVkx3W/LojIS67OoZSjrNsXxbB5u2hWqRCfPFwrzcVUXGrnLJjWFXIWsk2/ULZxhnZTpWgepj/RgCkD6uMlMPjHbfSZuJmwkxccHFi5kqU3cImIN3ACaGiMOZLWdnoDl3JX/0Scp+cPmyhVwI85zzQmj6+PtYGMgTUfwbrPoNx90PNH8CvgkF0nJqcwc/NRvlq5jwvxifSsX5qX21alcJ6MTSutnM9db+BqDRy8VdFXyl2diIln4JSt5PHNxtSBDawv+okJtpE7u+dCnceh81eQzXH3D/h4e9G/STm6BZTg61UHmL4xnN93nuT5VpUY2LSc5TeoqfSz+ox/MhBijPn2Ju8NBgYDlClTpt6RI/rdoNzH+fhEHv1+AyfPJzD3mSZULWbxcoRxZyDoMTi+Bdq8a5t3x8ldTgejYvl4cRgrwyIpXdCPYR2r0bFGMffo6lKAGy69KCLZgQigujHm9K221a4e5U4uJyXTf/IWth05x7QnGtCkYiFrA0XthRmPQuxpeOgHqP6gS5v/c/8ZPlgYyt7TF2lQriAjutzrPvcveDh3XHqxI7az/VsWfaXcSUqK4bW5f7Pp0Fk+717b+qJ/cA1MbAuJ8TBgscuLPkCzyoVY9J9mfPhQDQ5GxdJ17J+8Omcnpy8kuDyLSh8rC/9jQJCF7St1xz5fvpf5OyIY2r4qD9YpaW2YbVPhp0cgX0nbyJ1S9SyLks3biz4Ny7JmaEsG31eBBTsiaDVqLV+v2k/8lWTLcqmbs6Twi0guoC0wz4r2lcqIHzcdYdzag/RpWIbnWla0LkhKCiwfAb8PgYqtbEsk5nePG8by+vowrFM1VrzcnOaVC/Plin20/mIt83ec0PH/bsSSwm+MiTPG+BtjzlvRvlJ3akXoad6Zv5vW9xThva7VrbuAeSUOfu4LG76G+oPgsdngm9eaLLdQ1j8X3/etx6zBjSiQKztDZu3g4XEbCDl6zupoCr1zV6nb2nEshheDQqhZMh/f9K5DNm+L/ttcOAlTOsGeRdDhE+g0CrytHpF9a40q+LPghWZ81r0Wx8/F8/B3GxgyazsRMfFWR/NougKXUrdwJDqOh7/bQM4c3sx7tql1Nyud2gUze0J8DHSfBFU7WpPjLsReTuL7tQeZsP4QAE83r8DTLSqSK4d7f3llZu44qkcpt3Y27goDpmwlxRimDWxgXdHftwwmd7DdlfvE0kxZ9AFy58jGq+2rsuqVFrSrXoyvVx+g1ai1zN12nJTUC8Arp9LCr9RNJCQmM2jaViJi4pnYP5AKhXNbE2TzDxDUC/wrwlOroXgta3I4UKkCOfnmsTr88mxjiuf349U5O+k29i+2HD5rdTSPoYVfqVSSUwxDZm1n+7EYxvQKoF7ZghaESILFQ2HJa1ClAwxcAnmLuz6HE9UrW5Bfn23C6J4BRF28TI8fNvLcjG0cO3vJ6mhZnnauKXUdYwwfLAxl2T+nebvLvXSoYUGxvXwR5j4B+5dD4xeg7fvglTXnwfHyEh6sU5L21Ysxft0hvv/jICtDI3miWXmeb1XR+vmPsig941fqOhPXH2bqhnAGNSvPE83Kuz5AzDGY1B4OrIIuX0H7D7Ns0b+eX3ZvhrSpzJpXW9KldnG+/+MgrUatJWjLUZK1/9/htPArZbfw7wg+XBxG55rFebNTNdcHOBFiWzjl/DHoMwcCn3B9BosVy+fLlz0CmP98U8r552LYvF10/no9Gw6csTpalpLuwi8ifiJS1ZlhlLLKlsNneXn2TuqXK8AXPWrj5eXiG7RCF9jG6GfLAU8uh0qtXdu+m6ldOj9znmnMt73rcDEhid4TN/PU9GAOn4mzOlqWkK7CLyIPADuApfbnASKywJnBlHKVA5EXeWp6MKUK+jGhX6Br55U3Bv4cbbsbt1gNGLQKiljw04YbEhG61CrBqldaMLR9VTYcOEO7r/7gg4WhnL+UaHW8TC29Z/zvAg2AGABjzA7Agg5QpRwr8kIC/Sdvxcfbi2kDG5A/p+MWLrmt5ET4/T+w8h2o/hD0/x1yF3Fd+5mEr483z7eqxJqhLXm4Tikm/3WYlqPW8OPGcJKSU6yOlymlt/An3mReHb3iojK1uMtJPDFtK+cuXWHKgPqULpjTdY3Hn7PNrBkyHe57FR6ZDD5+rms/EyqSx5dPu9di4YvNqFosDyPm/0PHMetZuzfS6miZTnoL/z8i0hvwFpHKIvINsMGJuZRyqqTkFJ6fGULYyYuM7V3XtQuHnD0Mk9rBkQ3w4DhoPQK8dJxFelUvkY+gpxrxQ996XElOYcCUrQyYsoUDkRetjpZppPdf24tAdeAyMBM4D7zkrFBKOZMxhuG/7Wbt3ihGPliDVve4sHvl6GbbyJ3YSOj3GwT0dl3bWYiI0L56MZb/tzlvdarGtiPnaD96Pe/M3825uCtWx3N7t52kTUS8gZXGmFauifRvOkmbcqSvV+3nyxX7ePH+SrzSzoUD1XbNhd+esy2c0nsOFKrkurazuOjYy3y1ch8zNx8ld45sDGlThb6NypI9m2f/JJXhSdqMMclAiojoIpoq05u77ThfrtjHw3VL8nLbKq5p1BhY+yn88iSUCrSN3NGi71D+uXMw8sGaLBnSnNql8/PBwlDaj17HytDTugDMTaRrWmYRmQ/UAVYA1wbSGmP+k6FGRfIDE4Ea2C4SP2GM2ZjW9nrGrxxh/f4oBk7ZSqMK/kweUN81Z4NJl2HBi/D3bKj9GDwwxjZWXzmNMYa1e6P4YFEoh6LiaFrJn+Gd76VacfdbsMbZ0jrjT+9cPfNw7DKJY4ClxpjuIpIdcOFwCuWJQiMu8OxPIVQqkpvvHq/rmqIfFw2z+8DRjXD/cNvoHatW7vIgIkKre4rQrHIhZmw6wlcr99P56/X0rF+GV9pVoVBu/eJN90Is9gJ99WfjvcaYDN1BYe8y2gFUMOlsXM/41d2IiInnoe/+wkuEec81oXg+FwybPLMfZjwKFyLgoXFQ4xHnt6luKubSFcas2s+PG4/g6+PNS20qM+i+ClbHcom7WohFRFoC+4GxwHfAPhFpnsEs5YEoYIqIbBeRifbF11O3OVhEgkUkOCoqKoNNKU93Pj6RAVO2cOlyMlMG1ndN0T+8zjZy5/JFGLBQi77F8ufMzjsPVGfZf5vTsHxBTl9IsDqS5dLbx78N6G2M2Wt/XgUIMsbUu+MGRQKBTUBTY8xmERkDXDDGjEjrM3rGrzLiclIyAyZvJfjIWaYNbECTSoWc3+j2n+D3IVCwIvT5GQqUc36b6o4kJadYt26yi93t0os+V4s+gDFmH5DRibKPA8eNMZvtz+cCdTO4L6VuKiXF8Prcv9l4KJrPutdyftFPSYGV78L856HcfbaJ1rTouyVPKfq3kt6Lu8EiMhH4yf68D5ChU3BjzCkROSYiVe1fJq2B0IzsS6m0fL58L7/tiGBo+6o8VKeUcxtLjIdfn4bQ+VBvAHQaBd66gIhyX+kt/M8CzwNXh2+ux9bXn1EvAjPsF4wPAQPvYl9K3eCnTUcYt/YgvRuW4bmWFZ3b2MXTMOsx21z67UbaVszSkTvKzaW38GcDxhhjvoRrd/NmeEyUfXbPf/U7KXW3Voae5u35u2l9TxHe71odcWYRPh0KM3vApWjo+RNU6+K8tpRyoPR2dq0Crh8O4QesdHwcpTJux7EYXgzaTo2S+fimdx3n9uUeWGmbaC05EQYu1qKvMjnrjxkAABXmSURBVJX0/s/wNcbEXn1if6w3XSm3cSQ6jienbqVQnuxM6l+fnNnT+8NsBmydCDN62C7ePrUaStRxXltKOUF6C3+ciFwbeWMfkhnvnEhK3ZmzcVcYMGUrycYwdWADCudx0p2ZKcmwdBgsegUqtYEnltgmXFMqk0nvadEQYI6IRNifFwd6OieSUumXkJjMoGlbORETz8xBDalYOLdzGrocC78Mgn1LoOGz0P5D8HLhEo1KOVB6C395bJO0lQEeBhqiK3ApiyWnGF6atYPtx2L4rnddAssVdE5D509AUE84/Y9tqGaDp5zTjlIukt6unhHGmAtAfqAVtqGc45yWSqnbMMbwwcJQlv5zihGd76VjzeLOaShih236hbOHoffPWvRVlpDewp9s/70zMMEYswhw4arUSt1o0p+HmbohnCebleeJZuWd08ieRTClI4g3PLEMKrd1TjtKuVh6C/8JEfkBW7/+YhHJcQefVcqhFv19kpGLwuhUsxhvdarm+AaMgQ3fwqw+UPge28idYjUc345SFklv8e4BLAPaG2NigILAUKelUioNW8PP8t+fdxBYtgBf9gjAy8vBN2glJ8LC/8Lyt6DaAzBgEeQp6tg2lLJYui7uGmMucd1CLMaYk8BJZ4VS6mYORMYyaFowpQr4MaFfIL4+Dh5Vk3Ae5gyAg6uh6UvQ+h3w0h9sVdbjxLtclHKcyIsJ9J+8BR9vL6YNbECBXA6+xHTuiG36hegD0PUbqNvPsftXyo1o4VduL+5yEk9M3crZuCvMfroRpQs6+KbxY1ttE60lX4HH50GFFo7dv1JuRgu/cmtJySm8MDOE0IgLTOwfSK1S+R3bwO558NuzkKcY9F4Mhavc/jNKZXLagancljGGEfN3s2ZvFCMfrMn99zjwIqsxsG4UzB0IxQNg0Got+spj6Bm/clvfrj5A0JZjvNCqEr0blnHcjpOu2JZH3DkTaj4KXb8FH1/H7V8pN6eFX7mlX7Yd54sV+3i4TkleaefAM/FLZ2F2XzjyJ7QcBi1e14VTlMexpPCLSDhwEdsdwUk3WwxYea4/95/h9V/+pmklfz55pJbjFlOJPggzHoXzx+DhCVCrh2P2q1QmY+UZfytjzBkL21duKDTiAs/8tI1KRXIz7vF6ZM/moMtQ4X/B7D6AQL8FULaxY/arVCakXT3KbUTExDNw6hZy58jGlIH1yevrgAXLL1+EP7+Cv762LZzS52coWOHu96tUJmZV4TfAchExwA/GmPGpNxCRwcBggDJlHHhhT7ml8/GJDJyylUuXk5nzbGOK5/O7/YduJSUZdsyE1R9A7GnbRdxOn4NfAccEVioTs6rwNzPGnBCRIsAKEdljjFl3/Qb2L4PxAIGBgTr3fxZ2JSmFZ37cxqEzsUwb2IB7iuW9ux0eXg/LhsGpXVCqPvSaCaX0MpJSV1lS+I0xJ+y/R4rIr0ADYN2tP6WyImMMr83dycZD0XzVszZNKhXK+M7OHoLlI2DPQshbCh6ZBDUe0VE7SqXi8sIvIrkAL2PMRfvjdsD7rs6h3MPny/by244IhravykN1SmVsJwnnbTdjbf4evHyg1XBo8gL43GV3kVJZlBVn/EWBX+1D9LIBM40xSy3IoSw2Y/MRvlt7kMcalOG5lhXvfAfJSRAyDdZ8BJeiIaAP3D8c8jppNS6lsgiXF35jzCGgtqvbVe5lVdhpRvy2m/vvKcIH3arf+Vj9g6th2VsQGQplm0L7j6BEgHPCKpXF6HBO5XI7j8Xwwszt1CiZj2971yGb9x2M1T+zH5YPh31LIX9Z6DEdqnXVfnyl7oAWfuVSR6Mv8eS0rRTKk51J/euTM3s6/wleOgt/fAZbJ0A2P2jzHjR8RufYUSoDtPArlzkXd4UBU7aQlGKYOrABhfPkuP2HkhMheDKs/dh2EbduP2j1FuQu4vzASmVRWviVSyQkJjNoejDHY+KZOaghFQvnvvUHjIH9K2xr357ZB+Vb2PrxddFzpe6aFn7ldMkphpdm7SDk6Dm+612XwHIFb/2ByDBY9qbtAm7BitArCKp21H58pRxEC79yupGLQln6zylGdLmXjjVvMdQy7oxtaOa2KZAjD7T/GOoPgmwOXl9XKQ+nhV851cT1h5jyVzhPNC3Pk83K33yjpCuw5Qf443O4Emsr9i3egFz+rg2rlIfQwq+cZvGuk3y4OIxONYsxvHO1f29gDOxZBCtG2KZbqNQW2o2EIve4PqxSHkQLv3KKreFneWn2DuqVKcCXPQLw8krVP3/yb1s/fvh6KFQV+vwCldtYE1YpD6OFXzncgchYBk0LplQBPyb0C8TXx/v/b148DWtGQsiPtimSO42CegPBW/8pKuUq+r9NOVTkxQQGTNmCj7cwbWADCuSyX5hNTIBNY2H9l5CUAI2egxZDdX58pSyghV85TNzlJJ6cGkx07BVmP92I0gVz2vrxQ3+DFW9DzFGo2gnafgCFKlkdVymPpYVfOURScgovzAzhn4jzTOwfSK1S+eFEiK0f/+hGKFoD+s2HCi2tjqqUx9PCr+6aMYYR83ezZm8UHz1Uk/tLJMOvz8DOIMhVGB4YA3X6gpf37XemlHI6Lfzqro1dc4CgLccY0rwkveOD4JvRkJIETV+C+14B37tcSlEp5VCWFX4R8QaCgRPGmC5W5VB3Z17Icb5YvoeRFfbQZ89QuHAC7u1mmz2zYBo3bCmlLGXlGf8QIAzQ08FM6q8DZwj6ZS4r8sykUsReKF4bHp4A5ZpaHU0pdQuWFH4RKQV0Bj4EXrYig7o7+/eFcn7GK8zx2UBKjqLQeRzU6gVed7CoilLKElad8Y8GXgPypLWBiAwGBgOUKVPGRbHU7cRdjGHX7HcJOPYTpUW42PC/5Ln/Vchxm2mWlVJuw+WFX0S6AJHGmG0i0jKt7Ywx44HxAIGBgcZF8VQaUpKT2bZgLOV2fkkjzhGcrw2lH/2EoqUrWx1NKXWHrDjjbwp0FZFOgC+QV0R+MsY8bkEWlQ6hG5eQfeVb1E8+yN5sVYnuMInAwNZWx1JKZZDLC78xZhgwDMB+xv+qFn33dOJQGKd/eY26ces4RSGC631Gvc5PIdqPr1SmpuP41b9cPH+W3bNGUC9iFgXwZlO5Z6jdYzjFcqV5SUYplYlYWviNMWuBtVZmUP+XnJRE8K9jqPzPaBpzga0FOlCux6c0KlHO6mhKKQfSM34FwO7188m15m0apoQT5lOds50+oX6d5lbHUko5gRZ+D3ds/06if32dgEsbiZAibG84moD2/bUfX6ksTAu/hzp/NoqwWW9R7/RcCpCdjRX/Q51H36CEXy6roymlnEwLv4dJvHKZkHlfUnXPtzQwcQT7d6FCj49pXKy01dGUUi6ihd+D/L1mDvnWv0vDlOP8k7020Q98RoOajayOpZRyMS38HuBIWDDn579OrYRgjktxdjT9jtqtH9N+fKU8lBb+LOxc1En2zX6TelG/UUB82VT5Fep2f41SOXytjqaUspAW/izoyuUEQuZ+yr37v6eeSWBb4Qep0vMjGhUubnU0pZQb0MKfhZiUFHauCqLQhg9oZE7yt28g+bp9RsNq9ayOppRyI1r4s4hDuzdx6ffXCbi8gyNepdnZfCK1Wz1qdSyllBvSwp/JnTl1jEM/DyMweiEXJBeb73mDug+/TNnsOayOppRyU1r4M6mE+Di2z/mEmgcnUIcrbCnag2q9PqRhwcJWR1NKuTkt/JmMSUlh+7JpFNvyEY1NJDtyNcb/oU9pVLm21dGUUpmEFv5MZP+O9SQueoO6ibs57FWO3fdPJ+C+blbHUkplMlr4M4GoiHDCf36d+jFLOUteNld/m8CHhuCdTf/6lFJ3TiuHG4uPu8iOn0dSO3wKtUlmY4nHqd7zfRrm97c6mlIqE7NisXVfYB2Qw97+XGPMO67O4c5MSgrbFk2g9LZPaUw0IXmaU/Thz2hcoZrV0ZRSWYAVZ/yXgfuNMbEi4gP8KSJLjDGbLMjidvYEr0KWvklg0h4OeFckuvW31G3SyepYSqksxIrF1g0Qa3/qY/9lXJ3D3Zw6dpDjc14j8MJKzpCfLbVHEtj1Oby8va2OppTKYizp4xcRb2AbUAkYa4zZfJNtBgODAcqUKePagC4UdzmJH/44yB/rVhPkvZ5NpQdSs+e7NMiT3+poSqksypLCb4xJBgJEJD/wq4jUMMbsTrXNeGA8QGBgYJb7iSAlxTBv+wk+W7qHyIuX6Vq7ETGt/qZRsWJWR1NKZXGWjuoxxsSIyBqgA7D7dttnFVsOn+WDhaHsOnGegNL5Gfd4PeqVLWB1LKWUh7BiVE9hINFe9P2AtsCnrs5hhWNnL/HxkjAW7zpF8Xy+jOkVwAO1SuDlJVZHU0p5ECvO+IsD0+z9/F7Az8aYhRbkcJmLCYmMXXOQyX8exttLeLltFZ66rwJ+2fXCrVLK9awY1fM3UMfV7VohOcXwc/Axvli+lzOxV3ikbimGtq9KsXy6ApZSyjp6566TbDhwhvcXhrLn1EXqlyvA5AH1qVVKR+oopaynhd/BDp+J46PFYawIPU2pAn5816cuHWsUQ0T78ZVS7kELv4Ocj0/km1X7mbYxnOzeXrzWoSpPNC2Pr4/24yul3IsW/ruUlJxC0JajfLliHzHxifQMLM3L7apQJI/24yul3JMW/rvwx74oRi4MZX9kLI0r+DO8SzWql8hndSyllLolLfwZcCDyIiMXhbF2bxTl/HMyvm892t5bVPvxlVKZghb+O3Au7gqjV+7jp81HyZndm+Gdq9GvcTmyZ/OyOppSSqWbFv50uJKUwo+bjjBm5T7iriTTu0EZXmpTGf/cOayOppRSd0wL/y0YY1gVFsmHi8M4fCaO+yoXYkSXe6lSNI/V0ZRSKsO08Kch7OQFRi4K5a8D0VQsnIspA+rTsmph7cdXSmV6WvhTORN7mS+W72P21qPk9fPhva7V6d2wDD7e2o+vlMoatPDbXU5KZspf4YxdfYD4xGQGNCnPf1pXIn/O7FZHU0oph/L4wm+MYenuU3y8ZA9Hz16iTbUiDOtUjYqFc1sdTSmlnMKjC//uE+d5f2EoWw6fpWrRPPz0ZEOaVS5kdSyllHIqjyz8kRcS+HzZXuaGHKdgzux8+FANegaWJpv24yulPIBHFf6ExGQmrj/Ed2sPkpRsGHxfBZ6/vxJ5fX2sjqaUUi5jxdKLpYHpQFHAAOONMWOc2aYxht//PsmnS/ZwIiaeDtWLMazTPZT1z+XMZpVSyi1ZccafBLxijAkRkTzANhFZYYwJdUZj24+e44OFoYQcjaF6ibx80aM2jSr4O6MppZTKFKxYevEkcNL++KKIhAElAYcX/mHzdhG05SiF8+Tgs+61eKRuKbx1YXOllIeztI9fRMphW393803eGwwMBihTpkyG9l/WPycvtKrEMy0rkjuHR13OUEqpNIkxxpqGRXIDfwAfGmPm3WrbwMBAExwc7JpgSimVRYjINmNMYOrXLRm/KCI+wC/AjNsVfaWUUo7l8sIvtlnOJgFhxpgvXd2+Ukp5OivO+JsCfYH7RWSH/VcnC3IopZRHsmJUz5+ADq1RSimL6BwFSinlYbTwK6WUh9HCr5RSHkYLv1JKeRjLbuC6EyISBRzJ4McLAWccGMfZMlNezeo8mSlvZsoKmSvv3WYta4wpnPrFTFH474aIBN/szjV3lZnyalbnyUx5M1NWyFx5nZVVu3qUUsrDaOFXSikP4wmFf7zVAe5QZsqrWZ0nM+XNTFkhc+V1StYs38evlFLqRp5wxq+UUuo6WviVUsrDZInCLyKTRSRSRHan8b6IyNcickBE/haRuq7OmCrP7fK2FJHz181e+rarM16XpbSIrBGRUBH5R0SG3GQbtzi+6czqTsfWV0S2iMhOe973brJNDhGZbT+2m+2r1rlcOrMOEJGo647tICuyXpfHW0S2i8jCm7znFsc1VaZb5XXssTXGZPpfQHOgLrA7jfc7AUuwzQraCNjs5nlbAgutPq72LMWBuvbHeYB9wL3ueHzTmdWdjq0Aue2PfbAtQdoo1TbPAd/bH/cCZrtx1gHAt1Yf1+vyvAzMvNnft7sc1zvI69BjmyXO+I0x64Czt9ikGzDd2GwC8otIcdek+7d05HUbxpiTxpgQ++OLQBhQMtVmbnF805nVbdiPV6z9qY/9V+rRFt2AafbHc4HW9sWMXCqdWd2GiJQCOgMT09jELY7rVenI61BZovCnQ0ng2HXPj+PGBcGusf3H6iUiUt3qMAD2H4frYDvbu57bHd9bZAU3Orb2H+93AJHACmNMmsfWGJMEnAf8XZvSJh1ZAR6xd/fNFZHSLo54vdHAa0BKGu+7zXG1u11ecOCx9ZTCn9mEYJtjozbwDfCbxXkQkdzY1kl+yRhzweo8t3KbrG51bI0xycaYAKAU0EBEaliZ51bSkfV3oJwxphawgv+fUbuUiHQBIo0x26xo/06lM69Dj62nFP4TwPXfkKXsr7klY8yFqz9WG2MWAz4iUsiqPCLig62QzjDGzLvJJm5zfG+X1d2O7VXGmBhgDdAh1VvXjq2IZAPyAdGuTXejtLIaY6KNMZftTycC9Vydza4p0FVEwoFZ2JZ5/SnVNu50XG+b19HH1lMK/wKgn330SSPgvDHmpNWh0iIixa72N4pIA2x/T5b8o7TnmASEGWO+TGMztzi+6cnqZse2sIjktz/2A9oCe1JttgDob3/cHVht7Ff7XCk9WVNd1+mK7RqLyxljhhljShljymG7cLvaGPN4qs3c4rhC+vI6+ti6fM1dZxCRIGyjNQqJyHHgHWwXnzDGfA8sxjby5ABwCRhoTVKbdOTtDjwrIklAPNDLqn+U2M5G+gK77P27AG8CZcDtjm96srrTsS0OTBMRb2xfQD8bYxaKyPtAsDFmAbYvsh9F5AC2AQG93Djrf0SkK5BkzzrAoqw35abHNU3OPLY6ZYNSSnkYT+nqUUopZaeFXymlPIwWfqWU8jBa+JVSysNo4VdKKQ+jhV8pOxEpJ2nMmKpUVqKFXyknst8VqpRb0cKv1I28RWSCfc755SLiJyIBIrLJPkHWryJSAEBE1opIoP1xIfst91fnTl8gIquBVSJSXETW2edR3y0i91n3x1NKC79SqVUGxhpjqgMxwCPAdOB1+wRZu7DdaX07dYHuxpgWQG9gmX2Cs9rAjlt+Uikn0x9DlbrRYWPM1cK8DagI5DfG/GF/bRowJx37WWGMubrmwlZgsn0Cud+u279SltAzfqVudPm6x8lA/ltsm8T//w/5pnov7uoD+8I7zbHNCDlVRPo5IKdSGaaFX6lbOw+cu65fvi9w9ew/nP9Pj9s9rR2ISFngtDFmArYpdS1d81kp7epR6vb6A9+LSE7gEP+ffXQU8LOIDAYW3eLzLYGhIpIIxAJ6xq8spbNzKqWUh9GuHqWU8jBa+JVSysNo4VdKKQ+jhV8ppTyMFn6llPIwWviVUsrDaOFXSikP8z9nrQA7v81RBQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U pandas-profiling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oiHGxPZT_vOG",
        "outputId": "4433d17f-38c0-4eff-b202-e57808ba4c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas-profiling in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Collecting pandas-profiling\n",
            "  Downloading pandas_profiling-3.1.0-py2.py3-none-any.whl (261 kB)\n",
            "\u001b[K     |████████████████████████████████| 261 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling) (1.4.1)\n",
            "Collecting multimethod>=1.4\n",
            "  Downloading multimethod-1.7-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling) (2.11.3)\n",
            "Collecting joblib~=1.0.1\n",
            "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
            "\u001b[K     |████████████████████████████████| 303 kB 27.6 MB/s \n",
            "\u001b[?25hCollecting requests>=2.24.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling) (0.5.1)\n",
            "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling) (1.3.5)\n",
            "Collecting visions[type_image_path]==0.7.4\n",
            "  Downloading visions-0.7.4-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling) (1.21.5)\n",
            "Requirement already satisfied: markupsafe~=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling) (2.0.1)\n",
            "Collecting PyYAML>=5.0.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 31.1 MB/s \n",
            "\u001b[?25hCollecting htmlmin>=0.1.12\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "Collecting tangled-up-in-unicode==0.1.0\n",
            "  Downloading tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling) (4.63.0)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling) (0.11.2)\n",
            "Collecting phik>=0.11.1\n",
            "  Downloading phik-0.12.0-cp37-cp37m-manylinux2010_x86_64.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 32.7 MB/s \n",
            "\u001b[?25hCollecting pydantic>=1.8.1\n",
            "  Downloading pydantic-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9 MB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (2.6.3)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (21.4.0)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.4->pandas-profiling) (7.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.0->pandas-profiling) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2018.9)\n",
            "Collecting scipy>=1.4.1\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.8.1->pandas-profiling) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.2.0->pandas-profiling) (1.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling) (2021.10.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling) (2.0.12)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.4->pandas-profiling) (1.2.0)\n",
            "Building wheels for collected packages: htmlmin, imagehash\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=53780691a45d183c393f5227724f45cd2b796fb8841d44b45d5631aa98fd8327\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=711d9084a6b256ee3a6a11c775b7e08870c61399406206cd7fb62b3e46866b3f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n",
            "Successfully built htmlmin imagehash\n",
            "Installing collected packages: tangled-up-in-unicode, scipy, multimethod, visions, joblib, imagehash, requests, PyYAML, pydantic, phik, htmlmin, pandas-profiling\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.0\n",
            "    Uninstalling joblib-1.1.0:\n",
            "      Successfully uninstalled joblib-1.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pandas-profiling\n",
            "    Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 htmlmin-0.1.12 imagehash-4.2.1 joblib-1.0.1 multimethod-1.7 pandas-profiling-3.1.0 phik-0.12.0 pydantic-1.9.0 requests-2.27.1 scipy-1.7.3 tangled-up-in-unicode-0.1.0 visions-0.7.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib",
                  "requests",
                  "scipy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pandas profiling\n",
        "import pandas as pd\n",
        "import pandas_profiling\n",
        "data=pd.read_csv('spam.csv 파일의 경로', 'encoding=latin1')\n",
        "data[:5]\n",
        "pr=data.profile_report()\n",
        "pr.to_file('./pr_report.html')\n",
        "print(pr)"
      ],
      "metadata": {
        "id": "49WhzPE2H0De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Machine learning workflow"
      ],
      "metadata": {
        "id": "oHjCfcSDfowa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds3PYpegs_58",
        "outputId": "8c4aeb23-ea6d-4151-813e-d424f0bb2364"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brOzs_pwzJS_",
        "outputId": "0852a16b-9366-4065-9e46-d2e19f4e77ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word_tokenizer in /usr/local/lib/python3.7/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Pl56YmMzkCa",
        "outputId": "1c67e1d5-804c-45db-8e81-baa7b7acc07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install WordPunctTokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbWEABMn5_Y1",
        "outputId": "5fdb021c-b123-4f87-9a9a-8253c87ae813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement WordPunctTokenizer (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for WordPunctTokenizer\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization/Tokenizing 전처리 되지 않은 데이터를 사용하고자 하는 용도에 맞게 tokenization, cleaning, normalization\n",
        "#corpus 에서 토긑이라고 불리는 단위로 나누는 작업을 토큰화라고 한다. 보통 의미있는 단위로 토큰을 정의한다. NLTK, KoNLPY 를 통해 실습 진행하면 토큰화 수행한다.\n",
        "#단어 토큰화 (Word Tokenizaion)\n",
        "\n",
        "from nltk_tokenize import WordPunctTokenizer\n",
        "from tensorflow.keras.processing.text import text_to_word_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "7PkhTIbCgZTT",
        "outputId": "6ea9a86a-2502-4838-b8e3-5c5dfa2f88c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-fde618ded608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#단어 토큰화 (Word Tokenizaion)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk_tokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordPunctTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_to_word_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk_tokenize'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화1:', word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "4bWS3_Yuzeld",
        "outputId": "863fd8a8-ab86-4d11-ac22-9e9173c0602e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-7cc55969d0d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'단어 토큰화1:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9efY2r1MAXLb",
        "outputId": "8e116b71-f9e2-4e9d-e0fc-e3668bf72a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화1:', word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24LHw194AneU",
        "outputId": "9de5b190-ce5b-442d-f8d1-17c25ad01c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화1: ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화1:', word_tokenize(\"Don't be fooled by Sally's fake smile.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKk4bWG3EJyL",
        "outputId": "bd88ef6b-1d9b-46e1-d73d-3bd13d9a9829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화1: ['Do', \"n't\", 'be', 'fooled', 'by', 'Sally', \"'s\", 'fake', 'smile', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUzm6tQZIMhS",
        "outputId": "477a6473-e3a8-4935-e628-6cc4521763d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOskZABmIdTf",
        "outputId": "a53fb693-4fd8-40cd-d91b-b3b6f313a00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiD9OHp_PflR",
        "outputId": "205cb7ad-4fac-4872-f715-a73cf59802ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOCFcke5PreP",
        "outputId": "c542515e-2363-49e7-e91b-4f6ba16dacf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word_tokenizer in /usr/local/lib/python3.7/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooP79rXqQNVC",
        "outputId": "d6ccdb64-06c9-443e-cccc-3d7f02df99d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "text=\"Don't be fooled by Sally's fake smile.\"\n",
        "print('단어토큰화3:', WordPunctTokenizer().tokenize(\"Don't be fooled by Sally's fake smile.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqRdopT_QRlv",
        "outputId": "5c0d1f31-171a-42e7-de15-94c78fef1079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어토큰화3: ['Don', \"'\", 't', 'be', 'fooled', 'by', 'Sally', \"'\", 's', 'fake', 'smile', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install text_to_word_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JL64o-XGuDE",
        "outputId": "ad3e7ed2-5110-46e1-f8dc-01eed895113c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement text_to_word_sequence (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for text_to_word_sequence\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "J7tz7YKqPM_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer"
      ],
      "metadata": {
        "id": "u1b5HXHALGO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ],
      "metadata": {
        "id": "U1Jd0Td5MGHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1=\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\""
      ],
      "metadata": {
        "id": "9kq6nfGdMLgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentence1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ebo90Ui0MbAC",
        "outputId": "f23beaac-068d-45e9-a197-995cef9e6bef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화2 :',WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPI9-KriMfaP",
        "outputId": "89b6d6f5-48cb-40db-b35c-4a4f393f0a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화2 : ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화3 :',text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C_J1hSCQauA",
        "outputId": "e5456a47-1c0a-4185-aa4f-99462a14587a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화3 : [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGdmVFl6QK3J",
        "outputId": "26dfeb35-cd24-432b-83e8-3ec93885d3f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word_tokenizer in /usr/local/lib/python3.7/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKQ242C9aNri",
        "outputId": "b499baeb-f55c-49af-e0eb-20dfa1f1498b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "Q69U8kSLbhR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "id": "MCMUPND3buXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTz5xBL0coj6",
        "outputId": "118c2eb2-d0b5-4422-cd18-2c669c4c15bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word_tokenizer in /usr/local/lib/python3.7/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "id": "76EL2aQKdBZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('단어 토큰화1 :',word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "8GYcqrzYduWQ",
        "outputId": "0e1a37dc-5653-4280-e9ae-01306b371530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-7199baa680c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'단어 토큰화1 :'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBCNHrnwxgm8",
        "outputId": "702f5757-5725-4c76-c525-0888857dfac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8WAbWApHzdRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ],
      "metadata": {
        "id": "0v3Egv9UdyhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5AlujOQy5ud",
        "outputId": "72168aee-4b6b-4dbf-e65b-fc5196dc90f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word_tokenizer\n",
            "  Downloading word_tokenizer-0.0.3.tar.gz (1.6 kB)\n",
            "Building wheels for collected packages: word-tokenizer\n",
            "  Building wheel for word-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word-tokenizer: filename=word_tokenizer-0.0.3-py3-none-any.whl size=1587 sha256=91431a80810101669e19edf78618a863faab4ae323f818a2e9bf4702811cf176\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/c7/e3/7ba49d646c59d1e3d0dfdb479978cc3c98a8a8ad53c2aa6b11\n",
            "Successfully built word-tokenizer\n",
            "Installing collected packages: word-tokenizer\n",
            "Successfully installed word-tokenizer-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer\n",
        "text = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print('트리뱅크 워드토크나이저 :',tokenizer.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "HVA03k9dygVP",
        "outputId": "6ea8fda0-3500-443d-8cda-27cbebf90341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-953643268b37>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install word_tokenizer\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtNsRpBjzjGV",
        "outputId": "afa7e320-3b22-4ee1-f72a-aff2842b3b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "605HdRif26rf",
        "outputId": "254b1877-fb44-48f3-a44f-6f360c6d27ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word_tokenizer in /usr/local/lib/python3.7/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "id": "LLOO5pH1CzXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer\n",
        "txt = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print('트리뱅크 워드토크나이저 :', tokenizer().tokenize(txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw4IbYQ227lY",
        "outputId": "6225f2c2-3469-4f74-862b-48f98a23de5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "트리뱅크 워드토크나이저 : ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhL3AIvtBPU1",
        "outputId": "164a6f92-9871-41fd-e251-60c763cdcad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word_tokenizer\n",
            "  Downloading word_tokenizer-0.0.3.tar.gz (1.6 kB)\n",
            "Building wheels for collected packages: word-tokenizer\n",
            "  Building wheel for word-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word-tokenizer: filename=word_tokenizer-0.0.3-py3-none-any.whl size=1589 sha256=001ba9f9c499544e6d60bc212ed49d8f3494d00f9687bbe7d919b029e3d82c32\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/c7/e3/7ba49d646c59d1e3d0dfdb479978cc3c98a8a8ad53c2aa6b11\n",
            "Successfully built word-tokenizer\n",
            "Installing collected packages: word-tokenizer\n",
            "Successfully installed word-tokenizer-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
        "print('문장 토큰화:', sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "id": "NncvUcEY6L1P",
        "outputId": "60ae295a-fdf0-4018-8520-d4d8178b0e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bb6cc72f60c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'문장 토큰화:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer = TreebankWordTokenizer\n",
        "txt = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print('트리뱅크 워드토크나이저 :', tokenizer().tokenize(txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF46WkYlFXqV",
        "outputId": "bd25256a-2263-4f87-f495-07b53c31ba93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "트리뱅크 워드토크나이저 : ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grKuAcUQFomD",
        "outputId": "b14f4d91-6dcb-427a-e282-3d788395f3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = \"His barber kept his word. He charged me $35.25. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
        "print('문장 토큰화:', sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FG4RWKLmFYm9",
        "outputId": "34328fe7-29a5-4c03-b4d7-f619e34d78d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 토큰화: ['His barber kept his word.', 'He charged me $35.25.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n",
        "print('문장 토큰화2 :',sent_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtSlc66AGfzq",
        "outputId": "8a3e2be6-5a1c-4a92-a54d-60911e64d0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장 토큰화2 : ['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3n_eXySG4Zq",
        "outputId": "2c6f330d-85a3-490c-9ac4-c41cd9433b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kss\n",
            "  Downloading kss-3.4.tar.gz (42.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.4 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from kss) (2019.12.20)\n",
            "Building wheels for collected packages: kss, emoji\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-3.4-py3-none-any.whl size=42449209 sha256=21d6a459780726c4c42fe4d275d80cf68ddccd888cc372f34e9ad25ca376dec1\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/8e/5b/305f0a804fba3943f353f1b0e3cb1fad39e4f5ae4893ea9590\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=fc3f08113a6f503d926859df8f2f2b1ccdf0a1f29770fbee0a65a17beae5e3a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built kss emoji\n",
            "Installing collected packages: emoji, kss\n",
            "Successfully installed emoji-1.7.0 kss-3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kss\n",
        "text = '딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다. 이제 해보면 알걸요?'\n",
        "print('한국어 문장 토큰화 :',kss.split_sentences(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVGpGW3sHdc9",
        "outputId": "c11e688e-0cb3-4700-bf9f-3459ca4b9ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Korean Sentence Splitter]: Initializing Pynori...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국어 문장 토큰화 : ['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어렵습니다.', '이제 해보면 알걸요?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83vPGs5YPJpn",
        "outputId": "88df9c5f-79bb-4637-dec4-33e477b00dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n",
        "tokenized_sentence = word_tokenize(text)\n",
        "\n",
        "print('단어 토큰화:', tokenized_sentence)\n",
        "print('품사 태깅:', pos_tag(tokenized_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsAzpzFKHenX",
        "outputId": "9e37d738-ca4d-459b-bf0d-d13fdb2a70f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화: ['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n",
            "품사 태깅: [('I', 'PRP'), ('am', 'VBP'), ('actively', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('Ph.D.', 'NNP'), ('students', 'NNS'), ('.', '.'), ('and', 'CC'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D.', 'NNP'), ('student', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOLk049YVRB0",
        "outputId": "c19e5666-f205-478d-f8a5-d122beb40b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 41.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "okt=Okt()\n",
        "kkma=Kkma()\n",
        "\n",
        "txt=\"열심히 코딩한 당신, 연휴에는 여행을 가봐요.\"\n",
        "\n",
        "print('OKT 형태소 분석:', okt.morphs(txt))\n",
        "print('OKT 품사 태깅:', okt.pos(txt))\n",
        "print('OKT 명사 추출:', okt.nouns(txt))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QGy36dpRp4T",
        "outputId": "eb1e066c-1150-47de-a52a-993dc29993c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OKT 형태소 분석: ['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요', '.']\n",
            "OKT 품사 태깅: [('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb'), ('.', 'Punctuation')]\n",
            "OKT 명사 추출: ['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "txt=\"열심히 코딩한 당신, 연휴에는 여행을 가봐요.\"\n",
        "\n",
        "print('OKT 형태소 분석:', Okt().morphs(txt))\n",
        "print('OKT 품사 태깅:', Okt().pos(txt))\n",
        "print('OKT 명사 추출:', Okt().nouns(txt))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWWYZHDzX7BT",
        "outputId": "3430c1f8-a89e-4a13-bb3c-97118d52badb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OKT 형태소 분석: ['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요', '.']\n",
            "OKT 품사 태깅: [('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb'), ('.', 'Punctuation')]\n",
            "OKT 명사 추출: ['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('꼬꼬마 형태소 분석:', Kkma().morphs(txt))\n",
        "print('꼬꼬마 품사 태깅:', Kkma().pos(txt))\n",
        "print('꼬꼬마 명사 추출:', Kkma().nouns(txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYmpyrzyZJR1",
        "outputId": "0076ca18-c22a-454f-c62f-a5fac5c12222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "꼬꼬마 형태소 분석: ['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요', '.']\n",
            "꼬꼬마 품사 태깅: [('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN'), ('.', 'SF')]\n",
            "꼬꼬마 명사 추출: ['코딩', '당신', '연휴', '여행']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re #함수 불러들이기\n",
        "txt= \"Somehwere over the rainbow, way up high. And the dreams that you dreamed of, Once in a lulluby, oh.\"\n",
        "\n",
        "#길이가 1~2인 단어들을 정규 표현식을 이횽하여 삭제\n",
        "shortword=re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
        "print(shortword.sub('',txt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DvtkBWeZ66x",
        "outputId": "ed341ea1-84b3-4a4d-b7d1-57077813080c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Somehwere over the rainbow, way high. And the dreams that you dreamed, Once lulluby.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7RUMfDyGVVu",
        "outputId": "98c5188c-46d9-49b7-a404-0141d056e33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install KoNLPy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtfz5RR7GduU",
        "outputId": "cd496b34-6a2e-4feb-997c-4fdc611253fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting KoNLPy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from KoNLPy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from KoNLPy) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->KoNLPy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, KoNLPy\n",
            "Successfully installed JPype1-1.3.0 KoNLPy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZxR570NGwLs",
        "outputId": "b5a4bba2-a22e-42ce-f507-89ecc59e9fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word_tokenizer\n",
            "  Downloading word_tokenizer-0.0.3.tar.gz (1.6 kB)\n",
            "Building wheels for collected packages: word-tokenizer\n",
            "  Building wheel for word-tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word-tokenizer: filename=word_tokenizer-0.0.3-py3-none-any.whl size=1590 sha256=99817841ee90ced76540e0cb0a3866db7bbc757cebb2cefd32d01cc2a121b779\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/c7/e3/7ba49d646c59d1e3d0dfdb479978cc3c98a8a8ad53c2aa6b11\n",
            "Successfully built word-tokenizer\n",
            "Installing collected packages: word-tokenizer\n",
            "Successfully installed word-tokenizer-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP4b2dfwHDSj",
        "outputId": "b80b8b6d-c538-4457-b9b1-ab78216096c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ],
      "metadata": {
        "id": "7Os1pRPMHYUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogg55teJIW7s",
        "outputId": "3df8fa16-0406-4c32-94b4-4d210e7e3353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "print('표제어 추출 전 :',words)\n",
        "print('표제어 추출 후 :',[lemmatizer.lemmatize(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hFpaNtyHYOt",
        "outputId": "e2a5dea1-39e0-46d1-c048-6136d0c2cdca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('dies', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7pmvC8YwHYJ-",
        "outputId": "4409b048-178b-4517-83af-e9ff2a6ee789"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'die'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('watched', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xNSfYJgPHYEQ",
        "outputId": "5d9e7329-3bfb-4de2-9a6c-ab5da64b9e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'watch'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('has','v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zOrvgBg1HX7k",
        "outputId": "3de4ed8e-09f2-42a2-dd19-d45f91a546af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'have'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "yg2PmIvvXobd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install word_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RGzDdZfW9n7",
        "outputId": "a70adad7-82fc-4314-9b3f-3475622fa09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: word_tokenizer in /usr/local/lib/python3.7/dist-packages (0.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6d7mSO5Xw6E",
        "outputId": "bf9abdb9-040b-4ca1-c519-8eb862fc1691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "sentence = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
        "tokenized_sentence = word_tokenize(sentence)\n",
        "\n",
        "print('어간 추출 전:', tokenized_sentence)\n",
        "print('어간 추출 후:', [stemmer.stem(word) for word in tokenized_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w7DuhJxHXvu",
        "outputId": "700bd298-732e-4c63-959b-ae02aed81a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전: ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
            "어간 추출 후: ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cnK8NnJWHXVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNYr22KoG9Ca",
        "outputId": "95e93e22-d221-4a51-b4e3-adbfb6b69992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from nltk.stem [nltk package 의 모듈] import WordNetLemmatizer [모듈의 함수]\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "print('표제어 추출 전 :',words)\n",
        "print('표제어 추출 후 :',[lemmatizer.lemmatize(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaL4yvk8EgQ1",
        "outputId": "2914b210-8aef-48c9-f02b-4e56966e84b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words =['formaize', 'allowance', 'electrical']\n",
        "\n",
        "print ('어간 추출 전:', words)\n",
        "print ('어간 추출 후:', [stemmer.stem(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fSuj9VsY2tv",
        "outputId": "fa18b805-5a94-4665-dbd9-d6a4669683ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "어간 추출 전: ['formaize', 'allowance', 'electrical']\n",
            "어간 추출 후: ['formaiz', 'allow', 'electr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "porter_stemmer=PorterStemmer()\n",
        "lancaster_stemmer=LancasterStemmer()\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "\n",
        "print('before extracting stems:', words)\n",
        "print('extracting stems with PorterStemmer:', [porter_stemmer.stem(word) for word in words])\n",
        "print('extracting stem with LancasterStemmer:', [lancaster_stemmer.stem(word) for word in words])\n",
        "\n",
        "\n",
        "#porter_stemmer = PorterStemmer()\n",
        "#lancaster_stemmer = LancasterStemmer()\n",
        "\n",
        "#words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "#print('어간 추출 전 :', words)\n",
        "#print('포터 스테머의 어간 추출 후:',[porter_stemmer.stem(w) for w in words])\n",
        "#print('랭커스터 스테머의 어간 추출 후:',[lancaster_stemmer.stem(w) for w in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hS1F4Lpeu8A",
        "outputId": "f451a70f-cd71-44a0-ee0c-da0179008e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before extracting stems: ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
            "extracting stems with PorterStemmer: ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
            "extracting stem with LancasterStemmer: ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_word_list=stopwords.words('english')\n",
        "print('number of stopswords:', len(stop_word_list))\n",
        "print('10 stops words', stop_word_list[:10])\n",
        "\n",
        "#NLTK 에서 불용어 stopwords 갯수 확인하기\n",
        "#from nltk.corpus import stopwords\n",
        "#from nltk.tokenize import word_tokenize \n",
        "#from konlpy.tag import Okt\n",
        "\n",
        "#stop_words_list = stopwords.words('english')\n",
        "#print('불용어 개수 :', len(stop_words_list))\n",
        "#print('불용어 10개 출력 :',stop_words_list[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtQLLWnYm0Kz",
        "outputId": "d6694b85-6a55-4765-82e0-0f3cf1fc5d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "number of stopswords: 179\n",
            "10 stops words ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Family is not an important thing. It's everything.\"\n",
        "stop_words=set(stopwords.words('english'))\n",
        "\n",
        "word_tokens = word_tokenize(sentence)\n",
        "\n",
        "result = []\n",
        "for word in word_tokens:\n",
        "  if word not in stop_words:\n",
        "    result.append(word)\n",
        "\n",
        "print('before removing stopwords:', word_tokens)\n",
        "print('after removing stopwords:', result)   \n",
        "\n",
        "#NLTK에서 불용어 제거하기\n",
        "#example = \"Family is not an important thing. It's everything.\"\n",
        "#stop_words = set(stopwords.words('english')) \n",
        "\n",
        "#word_tokens = word_tokenize(example)\n",
        "\n",
        "#result = []\n",
        "#for word in word_tokens: \n",
        "#    if word not in stop_words: \n",
        "#        result.append(word) \n",
        "\n",
        "#print('불용어 제거 전 :',word_tokens) \n",
        "#print('불용어 제거 후 :',result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNXOxmIQs4C2",
        "outputId": "ed8f3291-4ff5-45a6-cadf-7ee406c673ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before removing stopwords: ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
            "after removing stopwords: ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "\n",
        "sentence = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
        "stop_words = \"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\"\n",
        "\n",
        "stop_words=set(stop_words.split(' '))\n",
        "word_tokens=okt.morphs(sentence)\n",
        "\n",
        "result = [word for word in word_tokens if not word in stop_words]\n",
        "print('불용어 제거 전:', word_tokens)\n",
        "print('불용어 제거 후:', result)\n",
        "#okt = Okt()\n",
        "\n",
        "#example = \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
        "#stop_words = \"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\"\n",
        "\n",
        "#stop_words = set(stop_words.split(' '))\n",
        "#word_tokens = okt.morphs(example)\n",
        "\n",
        "#result = [word for word in word_tokens if not word in stop_words]\n",
        "\n",
        "#print('불용어 제거 전 :',word_tokens) \n",
        "#print('불용어 제거 후 :',result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIoRyUTYzpHv",
        "outputId": "1ddf876a-b72d-48c9-d6bf-215fcfcd1d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "불용어 제거 전: ['고기', '를', '아무렇게나', '구', '우려', '고', '하면', '안', '돼', '.', '고기', '라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살', '을', '구울', '때', '는', '중요한', '게', '있지', '.']\n",
            "불용어 제거 후: ['고기', '하면', '.', '고기', '라고', '다', '아니거든', '.', '예컨대', '삼겹살', '을', '중요한', '있지', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "r=re.compile(\"a.c\")\n",
        "r.search(\"apc\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy5kstyUTgBy",
        "outputId": "3a41e6b0-a72e-4c7f-896a-8dc38e79f834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='apc'>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "r=re.compile(\"ab?d\")\n",
        "r.search(\"ad\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PfjtvG1U0t7",
        "outputId": "9f25bf6a-492c-4253-d5f7-64a38706b190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ad'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "r=re.compile('ab*c')\n",
        "r.search('abbbc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43Fc2V_4MC_k",
        "outputId": "07c46d9a-c5f9-4d46-8fab-8871756b79bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 5), match='abbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=re.compile('ab+c')\n",
        "r.search('abc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5jKzl-kMTI2",
        "outputId": "746d4319-1c24-4219-b1f3-c15191765ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abc'>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=re.compile('^ab')\n",
        "r.search('abtsq')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUjuWY2bHixj",
        "outputId": "29e4b5d9-a415-49f3-f146-f8ac7418bcd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 2), match='ab'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=re.compile('ab{2}c')\n",
        "r.search('abbc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNkl9vl1H8H3",
        "outputId": "e257f166-00a5-4476-a9d7-7a26fa212b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 4), match='abbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=re.compile(\"ab{2,8}c\")\n",
        "r.search('abbbbbbbbc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWkNTU94JLpq",
        "outputId": "c7e24946-8fa7-4f7f-9827-b0df13da26f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 10), match='abbbbbbbbc'>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "r=re.compile(\"a{2,}bc\")\n",
        "r.search('aaabc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2jgSXKXLJSD",
        "outputId": "27662ffc-f2a2-416f-ee11-d3fa526e5816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 5), match='aaabc'>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=re.compile(\"[abc]\")\n",
        "r.search('bac')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z6kApvrPLnw",
        "outputId": "04ed034c-77c0-4d7a-b38e-1500983bb2e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 1), match='b'>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=re.compile(\"[a-z]\")\n",
        "r.search('QaaaczAC')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqFYTmEcPzS3",
        "outputId": "42a22735-06e0-429c-c5cc-b3c9eeb9d0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(1, 2), match='a'>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=re.compile(\"[^abcde]\")\n",
        "r.search('bcdet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG1nx42_SG2K",
        "outputId": "5a9d2f4a-6638-4871-c3b1-56df7bb1337f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(4, 5), match='t'>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r=re.compile('ab.')\n",
        "r.match('abttck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1zlm9VPVozI",
        "outputId": "96c8e8ac-ff8f-498b-b8ce-62ee7d04e928"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(0, 3), match='abt'>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"apple strawberry watermelon cantelope banana\"\n",
        "re.split(\" \", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qntj4htWaakK",
        "outputId": "31f211ac-e311-4ab1-dc2a-07b96ccce475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apple', 'strawberry', 'watermelon', 'cantelope', 'banana']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"apple\n",
        "strawberry \n",
        "watermelon\n",
        "catelope\n",
        "banana\"\"\"\n",
        "re.split(\"\\n\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqOMLVfAV9QQ",
        "outputId": "a2cb203e-af66-4e75-8733-4044d211c1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apple', 'strawberry ', 'watermelon', 'catelope', 'banana']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"apple + strawberry + watermelon + cantelope + banana\"\n",
        "re.split(\" \\+ \", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QGWzAFIevYI",
        "outputId": "1681689a-85e4-4cdf-d148-5b9a1569ca69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apple', 'strawberry', 'watermelon', 'cantelope', 'banana']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"이름 : 김철수\n",
        "전화번호 : 010 - 1234 - 1234\n",
        "나이 : 30\n",
        "성별 : 남\"\"\"\n",
        "\n",
        "re.findall(\"\\d+\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aCYeACdfMan",
        "outputId": "ed9c4793-5496-40de-a025-12e95d28e78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['010', '1234', '1234', '30']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\"1234\n",
        "5678\n",
        "910\n",
        "1314\"\"\"\n",
        "re.findall(\"\\str+\", text) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At78uYfpg1nH",
        "outputId": "992333a7-db31-497c-cd8b-43ebc2b19ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "txt = \"Regular expression : A regular expression, regex or regexp[1] (sometimes called a rational expression)[2][3] is, in theoretical computer science and formal language theory, a sequence of characters that define a search pattern.\"\n",
        "preprocessed_txt=re.sub('[^a-zA-Z]', ' ', txt)\n",
        "print(preprocessed_txt)"
      ],
      "metadata": {
        "id": "fKdrFOw4ihtw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30b66835-24cb-4161-e741-15ae0a58f387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regular expression   A regular expression  regex or regexp     sometimes called a rational expression        is  in theoretical computer science and formal language theory  a sequence of characters that define a search pattern \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = \"\"\"100 John    PROF\n",
        "101 James   STUD\n",
        "102 Mac   STUD\"\"\"\n",
        "re.split('\\s+', txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6-rt3cdqHPU",
        "outputId": "42198300-e21f-4a3c-e0c8-bebf4f70e261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.split('\\s+', txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BDYP2kruHSv",
        "outputId": "0e8f39a5-1c4f-4c7c-a87e-7bb45728274a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', 'John', 'PROF', '101', 'James', 'STUD', '102', 'Mac', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('\\d+', txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLwUWStqrBY_",
        "outputId": "f971c767-f010-4043-ec20-2d3516ce5d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['100', '101', '102']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z]', txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNQPEwQotfwD",
        "outputId": "a94b5f34-b39f-4d53-c09a-d06b6870c710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['J', 'P', 'R', 'O', 'F', 'J', 'S', 'T', 'U', 'D', 'M', 'S', 'T', 'U', 'D']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z]{4}', txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTtcyha-xP3c",
        "outputId": "d9f1ef2e-fcdf-41da-fe4d-ba26b500abfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PROF', 'STUD', 'STUD']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re.findall('[A-Z][a-z]+',txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCuHxPEZxy8E",
        "outputId": "9d0e1e87-71fb-4595-bcaa-7fb864ac6e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['John', 'James', 'Mac']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "txt= \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"\n",
        "tokenizer1=RegexpTokenizer('[\\w]+')\n",
        "tokenizer2=RegexpTokenizer('\\s+', gaps=True)\n",
        "tokenizer3=RegexpTokenizer('\\s+')\n",
        "print(tokenizer1.tokenize(txt))\n",
        "print(tokenizer2.tokenize(txt))\n",
        "print(tokenizer3.tokenize(txt))\n",
        "#from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "#text = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop\"\n",
        "\n",
        "#tokenizer1 = RegexpTokenizer(\"[\\w]+\")\n",
        "#tokenizer2 = RegexpTokenizer(\"\\s+\", gaps=True) #gaps=True 를 안쓰면 공백들만 나온다\n",
        "\n",
        "#print(tokenizer1.tokenize(text))\n",
        "#print(tokenizer2.tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbjidoodyaUA",
        "outputId": "800d6358-2d2a-491c-9118-a7911a874926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Don', 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'Mr', 'Jone', 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
            "[\"Don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name,', 'Mr.', \"Jone's\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n",
            "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "processed_sentence=[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
        "\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts\n",
        "#import numpy as np\n",
        "#from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_sentences) #모든 단어가 고유한 정수로 변환되었습니다.\n",
        "encoded = tokenizer.texts_to_sequences(preprocessed_sentences) #모든 단어가 고유한 정수로 변환되었습니다.\n",
        "print(encoded)\n",
        "\n",
        "max_len = max(len(item) for item in encoded)\n",
        "print('최대 길이 :',max_len)\n",
        "\n",
        "for sentence in encoded:\n",
        "    while len(sentence) < max_len:\n",
        "        sentence.append(0) #가장 길이가 긴 문장의 길이는 7입니다. 모든 문장의 길이를 7로 맞춰주겠습니다. 이때 가상의 단어 'PAD'를 사용합니다. 'PAD'라는 단어가 있다고 가정하고, 이 단어는 0번 단어라고 정의합니다. 길이가 7보다 짧은 문장에는 숫자 0을 채워서 길이 7로 맞춰줍니다.\n",
        "\n",
        "padded_np = np.array(encoded)\n",
        "print(padded_np) #혹은 단순히 리턴값으로 padded_np 코드 입력해도 출력됨\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHacSm4k5f6r",
        "outputId": "7b448059-00cc-4a04-d9d0-5baec8460e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n",
            "최대 길이 : 7\n",
            "[[ 1  5  0  0  0  0  0]\n",
            " [ 1  8  5  0  0  0  0]\n",
            " [ 1  3  5  0  0  0  0]\n",
            " [ 9  2  0  0  0  0  0]\n",
            " [ 2  4  3  2  0  0  0]\n",
            " [ 3  2  0  0  0  0  0]\n",
            " [ 1  4  6  0  0  0  0]\n",
            " [ 1  4  6  0  0  0  0]\n",
            " [ 1  4  2  0  0  0  0]\n",
            " [ 7  7  3  2 10  1 11]\n",
            " [ 1 12  3 13  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "encoded=tokenizer.texts_to_sequences(processed_sentence)\n",
        "print(encoded)\n",
        "padded_front=pad_sequences(encoded)\n",
        "padded_front"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cucR8opM8Ee",
        "outputId": "acdd77af-268f-42fd-a65a-04cc616183b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  1,  5],\n",
              "       [ 0,  0,  0,  0,  1,  8,  5],\n",
              "       [ 0,  0,  0,  0,  1,  3,  5],\n",
              "       [ 0,  0,  0,  0,  0,  9,  2],\n",
              "       [ 0,  0,  0,  2,  4,  3,  2],\n",
              "       [ 0,  0,  0,  0,  0,  3,  2],\n",
              "       [ 0,  0,  0,  0,  1,  4,  6],\n",
              "       [ 0,  0,  0,  0,  1,  4,  6],\n",
              "       [ 0,  0,  0,  0,  1,  4,  2],\n",
              "       [ 7,  7,  3,  2, 10,  1, 11],\n",
              "       [ 0,  0,  0,  1, 12,  3, 13]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "encoded=tokenizer.texts_to_sequences(processed_sentence)\n",
        "print(encoded)\n",
        "padded=pad_sequences(encoded, padding='post')\n",
        "padded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVHiYQWYPW9Z",
        "outputId": "5a29a4c6-e7f6-4649-9265-9d4bee770e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5,  0,  0,  0,  0,  0],\n",
              "       [ 1,  8,  5,  0,  0,  0,  0],\n",
              "       [ 1,  3,  5,  0,  0,  0,  0],\n",
              "       [ 9,  2,  0,  0,  0,  0,  0],\n",
              "       [ 2,  4,  3,  2,  0,  0,  0],\n",
              "       [ 3,  2,  0,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0,  0,  0],\n",
              "       [ 1,  4,  2,  0,  0,  0,  0],\n",
              "       [ 7,  7,  3,  2, 10,  1, 11],\n",
              "       [ 1, 12,  3, 13,  0,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(padded==padded_up).all() #True 리턴되어야 하는데 False 리턴 됨"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrhQxJFrPxfp",
        "outputId": "4e56835a-620a-4bbb-ea46-9aeb786c687e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded=pad_sequences(encoded, padding='post', truncating='post', maxlen=5)\n",
        "padded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBNj3FrJUmhE",
        "outputId": "aca24afd-272f-4385-d1f2-5ebf0148fa41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  5,  0,  0,  0],\n",
              "       [ 1,  8,  5,  0,  0],\n",
              "       [ 1,  3,  5,  0,  0],\n",
              "       [ 9,  2,  0,  0,  0],\n",
              "       [ 2,  4,  3,  2,  0],\n",
              "       [ 3,  2,  0,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0],\n",
              "       [ 1,  4,  6,  0,  0],\n",
              "       [ 1,  4,  2,  0,  0],\n",
              "       [ 7,  7,  3,  2, 10],\n",
              "       [ 1, 12,  3, 13,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "processed_sentence=[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(preprocessed_sentences) #Unless we have the 'fit_on_texts()', we have empty lists.\n",
        "last_value=len(tokenizer.word_index)+1 #What is \"word_index?\n",
        "encoded=tokenizer.texts_to_sequences(processed_sentence)\n",
        "padded1=pad_sequences(encoded, padding='post')\n",
        "padded2=pad_sequences(encoded, padding='post', maxlen=5)\n",
        "padded3=pad_sequences(encoded, padding='post', value=last_value)\n",
        "\n",
        "print(padded1)\n",
        "print(padded2)\n",
        "print(last_value)\n",
        "print(padded3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItPShllzU9ba",
        "outputId": "d1a55072-d7b7-4b0e-e61f-0949fc3496eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  5  0  0  0  0  0]\n",
            " [ 1  8  5  0  0  0  0]\n",
            " [ 1  3  5  0  0  0  0]\n",
            " [ 9  2  0  0  0  0  0]\n",
            " [ 2  4  3  2  0  0  0]\n",
            " [ 3  2  0  0  0  0  0]\n",
            " [ 1  4  6  0  0  0  0]\n",
            " [ 1  4  6  0  0  0  0]\n",
            " [ 1  4  2  0  0  0  0]\n",
            " [ 7  7  3  2 10  1 11]\n",
            " [ 1 12  3 13  0  0  0]]\n",
            "[[ 1  5  0  0  0]\n",
            " [ 1  8  5  0  0]\n",
            " [ 1  3  5  0  0]\n",
            " [ 9  2  0  0  0]\n",
            " [ 2  4  3  2  0]\n",
            " [ 3  2  0  0  0]\n",
            " [ 1  4  6  0  0]\n",
            " [ 1  4  6  0  0]\n",
            " [ 1  4  2  0  0]\n",
            " [ 3  2 10  1 11]\n",
            " [ 1 12  3 13  0]]\n",
            "14\n",
            "[[ 1  5 14 14 14 14 14]\n",
            " [ 1  8  5 14 14 14 14]\n",
            " [ 1  3  5 14 14 14 14]\n",
            " [ 9  2 14 14 14 14 14]\n",
            " [ 2  4  3  2 14 14 14]\n",
            " [ 3  2 14 14 14 14 14]\n",
            " [ 1  4  6 14 14 14 14]\n",
            " [ 1  4  6 14 14 14 14]\n",
            " [ 1  4  2 14 14 14 14]\n",
            " [ 7  7  3  2 10  1 11]\n",
            " [ 1 12  3 13 14 14 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install KoNLPy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ7T64C6v8Vb",
        "outputId": "423d19be-5b8c-493e-d146-633b24ba2f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting KoNLPy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 409 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from KoNLPy) (1.21.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from KoNLPy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->KoNLPy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, KoNLPy\n",
            "Successfully installed JPype1-1.3.0 KoNLPy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V7bDXS1w5xx",
        "outputId": "07d268f6-2978-42d7-97c4-bea47a91f2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly\n",
            "Successfully installed tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxBHIL0KxJp3",
        "outputId": "5ed36d8c-9a15-4298-c282-26b7bda56853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "2G5AXpGsxs-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install NLTK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3zB1r3jx-Zw",
        "outputId": "62baf338-242b-48ce-845a-85e215a723bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: NLTK in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from NLTK) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "UYCX4zp6xv9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt  #Okt 함수를 사용해 한국어 문장을 토큰화 한다. \n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "\n",
        "txt='나는 자연어 처리를 배운다'\n",
        "okt=Okt()\n",
        "tokens=okt.morphs(txt)\n",
        "print(tokens)\n",
        "\n",
        "integer_encoded=tokenizer.fit_on_texts(txt)\n",
        "print(integer_encoded)\n",
        "\n",
        "\n",
        "#from konlpy.tag import Okt \n",
        "\n",
        "#okt = Okt()  \n",
        "#tokens = okt.morphs(\"나는 자연어 처리를 배운다\")  \n",
        "#print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rasqxR0nRDE",
        "outputId": "911ee441-cd1a-4ea1-b556-3b5318fb247b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나', '는', '자연어', '처리', '를', '배운다']\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install NLTK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOrvK16-FZRF",
        "outputId": "b750d413-65b4-448b-8ce8-4e1ac4177061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: NLTK in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from NLTK) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "luledbYAFX9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "axRaE4UVFXdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "d295wEvGFXH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw4LBmxyGJO3",
        "outputId": "bfd6e956-86c2-4dd2-f5fc-b9e4b74def81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quVsd2MMLwvd",
        "outputId": "e5375749-a5f8-4c39-bdc5-ccb7d42a8cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text=\"A barber is a person. a barber is good person. a barber is huge person. he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. a barber kept his word. His barber kept his secret. But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\"\n",
        "sentences=sent_tokenize(raw_text)\n",
        "vocab = {}\n",
        "preprocessed_sentences = []\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "for sentence in sentences:\n",
        "    # 단어 토큰화\n",
        "    tokenized_sentence = word_tokenize(sentence)\n",
        "    result = []\n",
        "\n",
        "    for word in tokenized_sentence: \n",
        "        word = word.lower() # 모든 단어를 소문자화하여 단어의 개수를 줄인다.\n",
        "        if word not in stop_words: # 단어 토큰화 된 결과에 대해서 불용어를 제거한다.\n",
        "            if len(word) > 2: # 단어 길이가 2이하인 경우에 대하여 추가로 단어를 제거한다.\n",
        "                result.append(word)\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = 0 \n",
        "                vocab[word] += 1\n",
        "    preprocessed_sentences.append(result) \n",
        "print(preprocessed_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vlW7BDhFUBr",
        "outputId": "003beec4-c0e9-43fc-b6da-81a62d99352a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'], ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "txt='나는 자연어 처리를 배운다'\n",
        "okt=Okt()\n",
        "tokens=okt.morphs(txt)\n",
        "print(tokens)\n",
        "\n",
        "word_to_index = {word : index for index, word in enumerate(tokens)}\n",
        "print('Wordvocab:', word_to_index)\n",
        "\n",
        "def one_hot_encoding(word, word_to_index): #토큰을 \" \"에 입력 시 one_hot_vector 만들어내는 함수\n",
        "  one_hot_vector = [0]*(len(word_to_index))\n",
        "  index = word_to_index [word]\n",
        "  one_hot_vector[index] = 1\n",
        "  return one_hot_vector\n",
        "\n",
        "print(one_hot_encoding('자연어', word_to_index))\n",
        "print(one_hot_encoding('나', word_to_index))\n",
        "print(one_hot_encoding('는', word_to_index))\n",
        "print(one_hot_encoding('를', word_to_index))\n",
        "print(one_hot_encoding('배운다', word_to_index))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAJbhyBaO7SE",
        "outputId": "f434c8ea-5ad0-4bea-d29e-adc6000e1a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나', '는', '자연어', '처리', '를', '배운다']\n",
            "Wordvocab: {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n",
            "[0, 0, 1, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#keras 를 이용한 One_hot_encoding 방법\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "txt = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거가 최고야\"\n",
        "\n",
        "tokenizer= Tokenizer()\n",
        "tokenizer.fit_on_texts([txt]) #\n",
        "print('Vocab:', tokenizer.word_index) #요소와 인덱스의 쌍으로 리턴. 중복 단어 제외하고 출력. 한국어는 어간-어미 분리 출력 안함.\n",
        "\n",
        "encoded = tokenizer.texts_to_sequences([txt])[0] #단어를 정수 시퀀스로 변환\n",
        "print(encoded)\n",
        "\n",
        "one_hot_encoding2 = to_categorical(encoded) #단어에 대응하는 정수 시퀀스를 인자로 입력하여 1과 0*인 벡터로 출력\n",
        "print(one_hot_encoding2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqusk4eaO6Ix",
        "outputId": "62257a2c-602a-4db9-c1c2-6955c008107a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab: {'점심': 1, '나랑': 2, '먹으러': 3, '갈래': 4, '메뉴는': 5, '햄버거가': 6, '최고야': 7}\n",
            "[2, 1, 3, 4, 1, 5, 6, 7]\n",
            "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "HltLOwkg3XLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = (['a',1], ['b',2], ['c',3])\n",
        "x,y = zip(*sequences)\n",
        "print('X 데어터:', x)\n",
        "print('y 데어터:', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5S1Q5TeTTTV",
        "outputId": "c9258566-2dd3-414e-ed2b-9ac0f7b0f516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X 데어터: ('a', 'b', 'c')\n",
            "y 데어터: (1, 2, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 프레임 이용하여 분리하기\n",
        "\n",
        "import pandas as pd\n",
        "values = [['당신에게 들는 마지막 혜택!', 1],\n",
        "['안녕하세요. 내일 시간 괜찮으신지 확인 부탁드립니다', 0],\n",
        "['잘지내시지요, 선생님? 오랫만입니다.', 0],\n",
        "['(광고) 일급비밀 주식 정보 알려드립니다', 1]]\n",
        "\n",
        "columns=['메일 본문', '스팸 메일 유무']\n",
        "\n",
        "df=pd.DataFrame(values, columns=columns)\n",
        "df\n",
        "\n",
        "x=df['메일 본문']\n",
        "y=df['스팸 메일 유무']\n",
        "\n",
        "print('x 데이터:', x.to_list())\n",
        "print('y 데이터:', y.to_list())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brZk3oBcLTuu",
        "outputId": "1ddcfca2-9a00-4d2d-fcab-3fe3cbfc350b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x 데이터: ['당신에게 들는 마지막 혜택!', '안녕하세요. 내일 시간 괜찮으신지 확인 부탁드립니다', '잘지내시지요, 선생님? 오랫만입니다.', '(광고) 일급비밀 주식 정보 알려드립니다']\n",
            "y 데이터: [1, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "np_array = np.arange(0,16).reshape((4,4))\n",
        "print('전체 데이터 :')\n",
        "print(np_array)\n",
        "\n",
        "X = np_array[:, :3]\n",
        "y = np_array[:,3]\n",
        "\n",
        "print('X 데이터 :')\n",
        "print(X)\n",
        "print('y 데이터 :')\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GIufiIksfSc",
        "outputId": "b936e76a-4404-4d6e-ffa4-6b154362a73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 데이터 :\n",
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]\n",
            " [12 13 14 15]]\n",
            "X 데이터 :\n",
            "[[ 0  1  2]\n",
            " [ 4  5  6]\n",
            " [ 8  9 10]\n",
            " [12 13 14]]\n",
            "y 데이터 :\n",
            "[ 3  7 11 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install SciPy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A-F4jiMradm",
        "outputId": "94d857b2-4827-4d43-b218-4bb69cdc4d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SciPy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from SciPy) (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#사이킷 런으로 분리하기\n",
        "from SciPy import train_test_split\n",
        "\n",
        "X_train, X_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "X, y = np.arrange(10), reshape((5,2)), range(5)\n",
        "\n",
        "print('X 전체 데이터:')\n",
        "print(X)\n",
        "print('y 전체 데이터')\n",
        "print(list(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "_WKHslu-ocYC",
        "outputId": "c33eba03-d857-4b6d-f072-869dd71fbbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c01e8483f60d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#사이킷 런으로 분리하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSciPy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SciPy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1Kq1JFSyvG1",
        "outputId": "d310578b-bba1-4625-cb42-236373bba746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#수동으로 분리하기\n",
        "import numpy as np\n",
        "x, y = np.arange(0,24).reshape((12,2)), range(12)\n",
        "print('x 전체의 데이터:')\n",
        "print(x)\n",
        "print('y 전체의 데이터:')\n",
        "print(list(y))\n",
        "\n",
        "num_of_train = int(len(x) * 0.8)\n",
        "num_of_test = int(len(x) - num_of_train)\n",
        "print('훈련 데이터의 크기:', num_of_train)\n",
        "print('테스트 데이터의 크기:', num_of_test)\n",
        "\n",
        "x_test = x[num_of_test:] \n",
        "y_test = y[num_of_test:] \n",
        "x_train = x[:num_of_train]\n",
        "y_train = y[:num_of_train]\n",
        "print('x의 데이터:')\n",
        "print(x_test)\n",
        "print('y의 데이터:')\n",
        "print(list(y_test))\n",
        "\n",
        "\n",
        "\n",
        "#num_of_train = int(len(X) * 0.8) # 데이터의 전체 길이의 80%에 해당하는 길이값을 구한다.\n",
        "#num_of_test = int(len(X) - num_of_train) # 전체 길이에서 80%에 해당하는 길이를 뺀다.\n",
        "#print('훈련 데이터의 크기 :',num_of_train)\n",
        "#print('테스트 데이터의 크기 :',num_of_test)\n",
        "\n",
        "#X_test = X[num_of_train:] # 전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
        "#y_test = y[num_of_train:] # 전체 데이터 중에서 20%만큼 뒤의 데이터 저장\n",
        "#X_train = X[:num_of_train] # 전체 데이터 중에서 80%만큼 앞의 데이터 저장\n",
        "#y_train = y[:num_of_train] # 전체 데이터 중에서 80%만큼 앞의 데이터 저장\n",
        "\n",
        "#print('X 테스트 데이터 :')\n",
        "#print(X_test)\n",
        "#print('y 테스트 데이터 :')\n",
        "#print(list(y_test))\n",
        "\n",
        "## 길이가 3 이 나와야 하는데 내 거는 길이가 9. 왜 이런지 모름. "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSvoyPJHrpUw",
        "outputId": "1ec02e7e-258e-47a8-b37d-67c92ede90e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x 전체의 데이터:\n",
            "[[ 0  1]\n",
            " [ 2  3]\n",
            " [ 4  5]\n",
            " [ 6  7]\n",
            " [ 8  9]\n",
            " [10 11]\n",
            " [12 13]\n",
            " [14 15]\n",
            " [16 17]\n",
            " [18 19]\n",
            " [20 21]\n",
            " [22 23]]\n",
            "y 전체의 데이터:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "훈련 데이터의 크기: 9\n",
            "테스트 데이터의 크기: 3\n",
            "x의 데이터:\n",
            "[[ 6  7]\n",
            " [ 8  9]\n",
            " [10 11]\n",
            " [12 13]\n",
            " [14 15]\n",
            " [16 17]\n",
            " [18 19]\n",
            " [20 21]\n",
            " [22 23]]\n",
            "y의 데이터:\n",
            "[3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PyKoSpacing 인스톨\n",
        "pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "KpEKU_kB2JqQ",
        "outputId": "0c5b28c6-9fc8-43ea-916c-fda3bde6dbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-70a0ecba6e5f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install git+https://github.com/haven-jeon/PyKoSpacing.git\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent = '김철수는 극중 두 인격의 사나이 이광수 역을 맡았다. 철수는 한국 유일의 태권도 전승자를 가리는 결전의 날을 앞두고 10년간 함께 훈련한 사형인 유연재(김광수 분)를 찾으러 속세로 내려온 인물이다.'\n",
        "new_sent = sent.replace(\" \", '')\n",
        "print(new_sent)\n",
        "\n",
        "from pykospacing import Spacing\n",
        "spacing = Spacing()\n",
        "kospacing_sent_spacing(new_sent)\n",
        "print(sent)\n",
        "print(kospacing_sent)\n",
        "\n",
        "#new_sent = sent.replace(\" \", '') # 띄어쓰기가 없는 문장 임의로 만들기\n",
        "#print(new_sent)\n",
        "#from pykospacing import Spacing\n",
        "#spacing = Spacing()\n",
        "#kospacing_sent = spacing(new_sent) \n",
        "\n",
        "print(sent)\n",
        "print(kospacing_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "UBZdRMsE8VcO",
        "outputId": "55fc5a6f-da1a-416f-b22a-486ded961669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "김철수는극중두인격의사나이이광수역을맡았다.철수는한국유일의태권도전승자를가리는결전의날을앞두고10년간함께훈련한사형인유연재(김광수분)를찾으러속세로내려온인물이다.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-9b6fec21e951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpykospacing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpacing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mspacing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpacing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mkospacing_sent_spacing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_sent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pykospacing'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1xWKztJ1vds",
        "outputId": "d411787f-5673-43a5-ce4e-f970a48ef918"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upzESA6BA3_0",
        "outputId": "df411dfe-985c-4254-8f18-1cdb8cc45474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "df_avatar = pd.read_csv('avatar.csv', engine='python')\n",
        "df_avatar_lines = df_avatar.groupby('character').count()\n",
        "df_avatar_lines = df_avatar_lines.sort_values(by=['character_words'], ascending=False)[:10]\n",
        "top_character_names = df_avatar_lines.index.values\n",
        "\n",
        "df_character_sentiment = df_avatar[df_avatar['character'].isin(top_character_names)]\n",
        "df_character_sentiment = df_character_sentiment[['character', 'character_words']]\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "df_character_sentiment.reset_index(inplace=True, drop=True)\n",
        "df_character_sentiment[['neg', 'neu', 'pos','compound']] = df_character_sentiment['character_words'].apply(sid.polarity_scores).apply(pd.Series)\n",
        "df_character_sentiment\n",
        "                                            \n",
        "\n",
        "\n",
        "# reading and wragling data\n",
        "#df_avatar = pd.read_csv('avatar.csv', engine='python')\n",
        "#df_avatar_lines = df_avatar.groupby('character').count()\n",
        "#df_avatar_lines = df_avatar_lines.sort_values(by=['character_words'], ascending=False)[:10]\n",
        "#top_character_names = df_avatar_lines.index.values\n",
        "\n",
        "# filtering out non-top characters\n",
        "#df_character_sentiment = df_avatar[df_avatar['character'].isin(top_character_names)]\n",
        "#df_character_sentiment = df_character_sentiment[['character', 'character_words']]\n",
        "\n",
        "# calculating sentiment score\n",
        "#sid = SentimentIntensityAnalyzer()\n",
        "#df_character_sentiment.reset_index(inplace=True, drop=True)\n",
        "#df_character_sentiment[['neg', 'neu', 'pos', 'compound']] = df_character_sentiment['character_words'].apply(sid.polarity_scores).apply(pd.Series)\n",
        "#df_character_sentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "iEZhWiRP1fTu",
        "outputId": "acc9013e-0e7c-4b9c-b9d2-8f44414ad177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     character                                    character_words    neg  \\\n",
              "0       Katara  Water. Earth. Fire. Air. My grandmother used t...  0.130   \n",
              "1        Sokka  It's not getting away from me this time.  Watc...  0.000   \n",
              "2       Katara                                       Sokka, look!  0.000   \n",
              "3        Sokka  Sshh! Katara, you're going to scare it away.  ...  0.200   \n",
              "4       Katara                          But, Sokka! I caught one!  0.000   \n",
              "...        ...                                                ...    ...   \n",
              "7073      Zuko  At least you don't look like a boar-q-pine! My...  0.183   \n",
              "7074      Suki              And why did you paint me firebending?  0.000   \n",
              "7075     Sokka  I thought it looked more exciting that way.  O...  0.000   \n",
              "7076      Iroh  Hey, my belly's not that big anymore. I've rea...  0.000   \n",
              "7077      Toph                 Well I think you all look perfect!  0.000   \n",
              "\n",
              "        neu    pos  compound  \n",
              "0     0.804  0.066   -0.6874  \n",
              "1     1.000  0.000    0.0000  \n",
              "2     1.000  0.000    0.0000  \n",
              "3     0.800  0.000   -0.5411  \n",
              "4     1.000  0.000    0.0000  \n",
              "...     ...    ...       ...  \n",
              "7073  0.817  0.000   -0.4007  \n",
              "7074  1.000  0.000    0.0000  \n",
              "7075  0.687  0.313    0.7501  \n",
              "7076  1.000  0.000    0.0000  \n",
              "7077  0.396  0.604    0.7263  \n",
              "\n",
              "[7078 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecac0bfb-d5d2-4f63-bc9b-fe9c006da0d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>character</th>\n",
              "      <th>character_words</th>\n",
              "      <th>neg</th>\n",
              "      <th>neu</th>\n",
              "      <th>pos</th>\n",
              "      <th>compound</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Katara</td>\n",
              "      <td>Water. Earth. Fire. Air. My grandmother used t...</td>\n",
              "      <td>0.130</td>\n",
              "      <td>0.804</td>\n",
              "      <td>0.066</td>\n",
              "      <td>-0.6874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sokka</td>\n",
              "      <td>It's not getting away from me this time.  Watc...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Katara</td>\n",
              "      <td>Sokka, look!</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sokka</td>\n",
              "      <td>Sshh! Katara, you're going to scare it away.  ...</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.5411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Katara</td>\n",
              "      <td>But, Sokka! I caught one!</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7073</th>\n",
              "      <td>Zuko</td>\n",
              "      <td>At least you don't look like a boar-q-pine! My...</td>\n",
              "      <td>0.183</td>\n",
              "      <td>0.817</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.4007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7074</th>\n",
              "      <td>Suki</td>\n",
              "      <td>And why did you paint me firebending?</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7075</th>\n",
              "      <td>Sokka</td>\n",
              "      <td>I thought it looked more exciting that way.  O...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.687</td>\n",
              "      <td>0.313</td>\n",
              "      <td>0.7501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7076</th>\n",
              "      <td>Iroh</td>\n",
              "      <td>Hey, my belly's not that big anymore. I've rea...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7077</th>\n",
              "      <td>Toph</td>\n",
              "      <td>Well I think you all look perfect!</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.396</td>\n",
              "      <td>0.604</td>\n",
              "      <td>0.7263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7078 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecac0bfb-d5d2-4f63-bc9b-fe9c006da0d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecac0bfb-d5d2-4f63-bc9b-fe9c006da0d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecac0bfb-d5d2-4f63-bc9b-fe9c006da0d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Biden invites Ukrainian president to White House this summer\")\n",
        "print([(X.text, X.label_) for X in doc.ents])\n",
        "#nlp = spacy.load(\"en_core_web_sm\")\n",
        "#doc = nlp(\"Biden invites Ukrainian president to White House this summer\")\n",
        "#print([(X.text, X.label_) for X in doc.ents])\n",
        "\n",
        "#[('Biden', 'PERSON'), ('Ukrainian', 'GPE'), ('White House', 'ORG'), ('this summer', 'DATE')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaEQpzVUHroU",
        "outputId": "847088c0-1747-4d86-fd2f-e2f6bf28a9c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Ukrainian', 'NORP'), ('White House', 'ORG'), ('this summer', 'DATE')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "porter=PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n",
        "\n",
        "print(porter.stem('friendship'))\n",
        "print(lancaster.stem('friendship'))\n",
        "\n",
        "#from nltk.stem import PorterStemmer\n",
        "#from nltk.stem import LancasterStemmer\n",
        "\n",
        "# PorterStemmer\n",
        "#porter = PorterStemmer()\n",
        "\n",
        "# LancasterStemmer\n",
        "#lancaster = LancasterStemmer()\n",
        "#print(porter.stem(\"friendship\"))\n",
        "#print(lancaster.stem(\"friendship\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8A1-RMtMDYi",
        "outputId": "c732c421-e4a2-44b9-c756-365a80f97b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "friendship\n",
            "friend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = ['articles', 'friendship', 'studies', 'phones']\n",
        "for word in words:\n",
        "  print(lemmatizer.lemmatize(word))\n",
        "\n",
        "words2=['am', 'is', 'are', 'were', 'was']\n",
        "for word in words2:\n",
        "  print(lemmatizer.lemmatize(word, pos='v'))\n",
        "\n",
        "#from nltk import WordNetLemmatizer\n",
        "#lemmatizer = WordNetLemmatizer()\n",
        "#words = ['articles', 'friendship', 'studies', 'phones']\n",
        "#for word in words:\n",
        "#    print(lemmatizer.lemmatize(word))\n",
        "\n",
        "#from nltk import WordNetLemmatizer\n",
        "#lemmatizer = WordNetLemmatizer()\n",
        "#words = ['be', 'is', 'are', 'were', 'was']\n",
        "#for word in words:\n",
        "#    print(lemmatizer.lemmatize(word, pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9vF-Df5NYpb",
        "outputId": "336a77f6-5e78-4964-b85f-85b05baeb3c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "article\n",
            "friendship\n",
            "study\n",
            "phone\n",
            "be\n",
            "be\n",
            "be\n",
            "be\n",
            "be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install stylecloud"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNY0--ZhWKJE",
        "outputId": "84e628d1-a14a-4b28-fb73-94d019596106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stylecloud\n",
            "  Downloading stylecloud-0.5.2.tar.gz (262 kB)\n",
            "\u001b[K     |████████████████████████████████| 262 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from stylecloud) (1.5.0)\n",
            "Collecting icon-font-to-png\n",
            "  Downloading icon_font_to_png-0.4.1-py2.py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: palettable in /usr/local/lib/python3.7/dist-packages (from stylecloud) (3.3.0)\n",
            "Collecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stylecloud) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire->stylecloud) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire->stylecloud) (1.1.0)\n",
            "Requirement already satisfied: Pillow>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from icon-font-to-png->stylecloud) (7.1.2)\n",
            "Requirement already satisfied: requests>=2.12.5 in /usr/local/lib/python3.7/dist-packages (from icon-font-to-png->stylecloud) (2.23.0)\n",
            "Collecting tinycss>=0.4\n",
            "  Downloading tinycss-0.4.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.5->icon-font-to-png->stylecloud) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.5->icon-font-to-png->stylecloud) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.5->icon-font-to-png->stylecloud) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.12.5->icon-font-to-png->stylecloud) (3.0.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stylecloud) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stylecloud) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stylecloud) (1.21.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stylecloud) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stylecloud) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->stylecloud) (3.10.0.2)\n",
            "Building wheels for collected packages: stylecloud, fire, tinycss\n",
            "  Building wheel for stylecloud (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stylecloud: filename=stylecloud-0.5.2-py3-none-any.whl size=259508 sha256=7e6bdacc8e7b482d20966ea550b15f20d98e2c0fadef6b4b47f89bdb2db83a72\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/42/7a/f52b5f84c04196fd4c2a3dceeb1bbeaee1c93a4fe271b5eb41\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=1e77cb9824d99e4a47de2920db9d29ff1575996a2461b2abce587fbe1763c692\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "  Building wheel for tinycss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinycss: filename=tinycss-0.4-py3-none-any.whl size=43955 sha256=01724501c75582f56697a7acee59a5ac84eff2866c69b95844d0bb352e141c03\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/66/e8/e53d7a476011891fa51a5ee83a2d1852b19b258f975055429b\n",
            "Successfully built stylecloud fire tinycss\n",
            "Installing collected packages: tinycss, icon-font-to-png, fire, stylecloud\n",
            "Successfully installed fire-0.4.0 icon-font-to-png-0.4.1 stylecloud-0.5.2 tinycss-0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bag of Words\n",
        "#Classifiers and learning algorithms expect numerical feature vectors rather than raw text documents. \n",
        "#The Bag of Words (BoW) model is a representation that turns text into fixed-length vectors. \n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "text = [\"I love writing code in Python. I love Python code\",\n",
        "        \"I hate writing code in Java. I hate Java code\"]\n",
        "\n",
        "df = pd.DataFrame({'review': ['review1', 'review2'], 'text':text})\n",
        "cv = CountVectorizer(stop_words = 'english')\n",
        "cv_matrix = cv.fit_transform(df['text'])\n",
        "df_dtm = pd.DataFrame(cv_matrix.toarray(),\n",
        "                     index = df['review'].values,\n",
        "                     columns = cv.get_feature_names())\n",
        "df_dtm\n",
        "\n",
        "#import pandas as pd\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "#text = [\"I love writing code in Python. I love Python code\",\n",
        "#        \"I hate writing code in Java. I hate Java code\"]\n",
        "#df = pd.DataFrame({'review': ['review1', 'review2'], 'text':text})\n",
        "#cv = CountVectorizer(stop_words='english')\n",
        "#cv_matrix = cv.fit_transform(df['text'])\n",
        "#df_dtm = pd.DataFrame(cv_matrix.toarray(),\n",
        "#                      index=df['review'].values,\n",
        "#                      columns=cv.get_feature_names())\n",
        "#df_dtm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "BO-B-ZA0XPlc",
        "outputId": "f98b8e10-20fe-4f22-890b-2ec84dae025b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         code  hate  java  love  python  writing\n",
              "review1     2     0     0     2       2        1\n",
              "review2     2     2     2     0       0        1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1843f1cb-dc4e-4f67-98f7-e06690f4efbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>hate</th>\n",
              "      <th>java</th>\n",
              "      <th>love</th>\n",
              "      <th>python</th>\n",
              "      <th>writing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>review1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1843f1cb-dc4e-4f67-98f7-e06690f4efbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1843f1cb-dc4e-4f67-98f7-e06690f4efbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1843f1cb-dc4e-4f67-98f7-e06690f4efbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "text = [\"I love writing code in Python. I love Python code\",\n",
        "        \"I hate writing code in Java. I hate Java code\"]\n",
        "df = pd.DataFrame({'review': ['review1', 'review2'], 'text':text})\n",
        "tfidf = TfidfVectorizer(stop_words='english', norm=None)\n",
        "tfidf_matrix = tfidf.fit_transform(df['text'])\n",
        "df_dtm = pd.DataFrame(tfidf_matrix.toarray(),\n",
        "                      index=df['review'].values,\n",
        "                      columns=tfidf.get_feature_names())\n",
        "df_dtm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "j0JnEzrBvwxt",
        "outputId": "a49bc3a0-36aa-45bd-9958-fd2c274322b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         code     hate     java     love   python  writing\n",
              "review1   2.0  0.00000  0.00000  2.81093  2.81093      1.0\n",
              "review2   2.0  2.81093  2.81093  0.00000  0.00000      1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e81b0a29-3ad6-46b2-9250-1245903acd96\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>hate</th>\n",
              "      <th>java</th>\n",
              "      <th>love</th>\n",
              "      <th>python</th>\n",
              "      <th>writing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>review1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>2.81093</td>\n",
              "      <td>2.81093</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.81093</td>\n",
              "      <td>2.81093</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e81b0a29-3ad6-46b2-9250-1245903acd96')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e81b0a29-3ad6-46b2-9250-1245903acd96 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e81b0a29-3ad6-46b2-9250-1245903acd96');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stylecloud\n",
        "stylecloud.gen_stylecloud(file_path='SJ_speech.txt',\n",
        "                          icon_name = \"fas fa-apple-alt\")"
      ],
      "metadata": {
        "id": "p_ciUROgVEH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import NLTK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "3GfaYwswneCY",
        "outputId": "2a857b0a-313a-4f80-84a2-e0085cb0259c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a3c41acc7797>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mNLTK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'NLTK'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "OUHITiMinlcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hosung Nam nltk\n",
        "\n",
        "text = 'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently — they’re not fond of rules. \\\n",
        "You can quote them, disagree with them, glorify or vilify them, \\\n",
        "but the only thing you can’t do is ignore them because they change things. \\\n",
        "They push the human race forward, and while some may see them as the crazy ones, we see genius, \\\n",
        "because the ones who are crazy enough to think that they can change the world, are the ones who do.'\n",
        "\n",
        "file = open(\"tmp.txt\", \"w\")\n",
        "file.write(text)\n",
        "file.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "xa6d_kVvnXoR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}